{"meta":{"title":"stpehen的博客","subtitle":null,"description":null,"author":"stpehen","url":"http://imwyy.github.io"},"pages":[{"title":"categories","date":"2017-12-11T07:01:16.000Z","updated":"2017-12-11T07:01:44.353Z","comments":true,"path":"categories/index.html","permalink":"http://imwyy.github.io/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2017-12-11T07:01:23.000Z","updated":"2017-12-11T07:02:18.655Z","comments":true,"path":"about/index.html","permalink":"http://imwyy.github.io/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-11T06:44:04.000Z","updated":"2017-12-11T07:02:27.209Z","comments":true,"path":"tags/index.html","permalink":"http://imwyy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"netty高性能调优","slug":"netty高性能调优","date":"2018-06-19T09:45:13.000Z","updated":"2018-06-19T09:45:56.926Z","comments":true,"path":"2018/06/19/netty高性能调优/","link":"","permalink":"http://imwyy.github.io/2018/06/19/netty高性能调优/","excerpt":"","text":"netty关于netty的学习和介绍，可以去github看官方文档，这里良心推荐《netty实战》和《netty权威指南》两本书，前者对于新手更友好，原理和应用都有讲到，多读读会发现很多高性能的优化点。 netty高性能优化点最近参加了阿里中间价性能比赛，为了提升netty写的servive mesh的网络通信的性能，最近几天查了书、博客（这里强力推荐netty作者的博客，干货真的很多），自己总结了如下一下优化点。如果有错误希望能指正。 注：这里所讨论的对应的netty版本为netty4 首先要明确要netty优化的几个主要的关注点。 减少线程切换的开销。 复用channel，可以选择池化channel zero copy的应用 减少并发下的竞态情况 接下来将细数一下总结的优化点 1. 尽可能的复用EventLoopGroup。这里就要涉及netty的线程模型了。netty实战的第七章里有很细致的阐释。简单说EventLoopGroup包含了指定数量（如果没有指定，默认是cpu核数的两倍，可以从源码中看到）的EvenetLoop，Eve netLoop和channel的关系是一对多，一个channel被分配给一个EventLoop，它生命周期中都会使用这个EventLoop，而EventLoop背后就是线程。见下图。 因此如果需要使用ThreadLocal保存上下文，那么许多channel就会共享同一个上下文。 因此不需要每次都new出一个EventLoopGroup，其本质上是线程分配，可以复用同一个EventLoopGroup，减少资源的使用和线程的切换。特别是在服务端引导一个客户端连接的时候。如下： 123456789101112131415161718192021222324252627ServerBootstrap bootstrap = new ServerBootstrap();bootstrap.group(new NioEventLoopGroup(), new NioEventLoopGroup()) .channel(NioServerSocketChannel.class) .childHandler(new SimpleChannelInboundHandler&lt;ByteBuf&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf byteBuf) throws Exception &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class) .group(ctx.channel().eventLoop()) .handler(new SimpleChannelInboundHandler&lt;ByteBuf&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; System.out.println(\"Received data\"); &#125; &#125;); ChannelFuture future = bootstrap.connect(new InetSocketAddress(xxx, 80)); future.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; // do something &#125; &#125;); &#125; &#125;);bootstrap.bind(new InetSocketAddress(8080)).sync(); 2. 使用EventLoop的任务调度在EventLoop的支持线程外使用channel，用 123456channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; channel.writeAndFlush(data) &#125;&#125;); 而不是直接使用channel.writeAndFlush(data)； 前者会直接放入channel所对应的EventLoop的执行队列，而后者会导致线程的切换。 3. 减少ChannelPipline的调用长度123456789public class YourHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) &#123; // BAD (most of the times) ctx.channel().writeAndFlush(msg); // GOOD ctx.writeAndFlush(msg); &#125;&#125; 前者是将msg从整个ChannelPipline中走一遍，所有的handler都要经过，而后者是从当前handler一直到pipline的尾部，调用更短。 同样，为了减少pipline的长度，如果一个handler只需要使用一次，那么可以在使用过之后，将其从pipline中remove。 4. 减少ChannelHandler的创建如果channelhandler是无状态的（即不需要保存任何状态参数），那么使用Sharable注解，并在bootstrap时只创建一个实例，减少GC。否则每次连接都会new出handler对象。 12345678910111213@ChannelHandler.Shareable public class StatelessHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) &#123;&#125;&#125;public class MyInitializer extends ChannelInitializer&lt;Channel&gt; &#123; private static final ChannelHandler INSTANCE = new StatelessHandler(); @Override public void initChannel(Channel ch) &#123; ch.pipeline().addLast(INSTANCE); &#125;&#125; 同时需要注意ByteToMessageDecoder之类的编解码器是有状态的，不能使用Sharable注解。 5. 减少系统调用（Flush）的调用flush操作是将消息发送出去，会引起系统调用，应该尽量减少flush操作，减少系统调用的开销。 同时也要减少write的操作， 因为这样消息会流过整个ChannelPipline。 6. 使用单链接对于两个指定的端点可以使用单一的channel，在第一次创建之后保存channel，然后下次对于同一个IP地址可以复用该channel而不需要重新建立。 你可能需要一个map来保存对于不同ip的channel，但是在初始化时这可能会有一些线程并发的问题。在这篇微信推文（https://mp.weixin.qq.com/s/JRsbK1Un2av9GKmJ8DK7IQ）中有提到对于这个的解决方案，在蚂蚁金服的sofa-bolt项目中有类似情形，不过不太理解。 123456789initialTask = this.connTasks.get(poolKey);if (null == initialTask) &#123; initialTask = new RunStateRecordedFutureTask&lt;ConnectionPool&gt;(callable); initialTask = this.connTasks.putIfAbsent(poolKey, initialTask); if (null == initialTask) &#123; initialTask = this.connTasks.get(poolKey); initialTask.run(); &#125;&#125; 7. 利用netty零拷贝，在IO操作时使用池化的DirectBuffer在bootstrap配置参数的时候，使用.option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT)来指定一个池化的Allocator，并且使用ByteBuf buf = allocator.directBuffer();来获取Bytebuf。 PooledByteBufAllocator，netty会帮你复用（无需release，除非你后面还需要用到同一个bytebuf）而不是每次都重新分配ByteBuf。在IO操作中，分配直接内存而不是JVM的堆空间，就避免了在发送数据时，从JVM到直接内存的拷贝过程，这也就是zero copy的含义。 8. 一些配置参数的设置ServerBootstrap启动时，通常 bossGroup 只需要设置为 1 即可，因为 ServerSocketChannel 在初始化阶段，只会注册到某一个 eventLoop 上，而这个 eventLoop 只会有一个线程在运行，所以没有必要设置为多线程。而 IO 线程，为了充分利用 CPU，同时考虑减少线上下文切换的开销，通常设置为 CPU 核数的两倍，这也是 Netty 提供的默认值。 在对于响应时间有高要求的场景，使用.childOption(ChannelOption.TCP_NODELAY, true)和.option(ChannelOption.TCP_NODELAY, true)来禁用nagle算法，不等待，立即发送。 9. 小心的使用并发编程技巧千万不要阻塞EventLoop！包括了Thead.sleep() CountDownLatch 和一些耗时的操作等等，尽量使用netty中的各种future。如果必须尽量减少重量级的锁的的使用。 在使用volatile时， 坏的： 1234567private volatile Selector selector;public void method() &#123; selector.select(); .... selector.selectNow();&#125; 好的：先将volatile变量保存到方法栈中，jdk源码中大量的使用了这种技巧。 12345678private volatile Selector selector;public void method() &#123; Selector selector = this.selector; selector.select(); .... selector.selectNow();&#125; 使用Atomic*FieldUpdater替换Atomic*。关于这个可以参考http://normanmaurer.me/blog/2013/10/28/Lesser-known-concurrent-classes-Part-1/。简单说，如果使用`Atomic*`，对于每个连接都会创建一个对象，而如果使用`Atomic*FieldUpdater`则会省去这部分的开销，只有一个`static final`变量。 12345678private static final AtomicLongFieldUpdater&lt;TheDeclaringClass&gt; ATOMIC_UPDATER = AtomicLongFieldUpdater.newUpdater(TheDeclaringClass.class, \"atomic\");private volatile long atomic;public void yourMethod() &#123; ATOMIC_UPDATER.compareAndSet(this, 0, 1);&#125; 10. 响应顺序的处理当使用了单链接，就有一个必须要解决的问题，将请求和响应顺序对应起来。因为所有的操作都是异步的，TCP是基于字节流的，所以channel接收到的数据无法保证和发送顺序一致。这个的解决方案就是，对于每个请求指定一个id，对于响应也携带该id。如果后发的请求的响应先到，则将其缓存起来（可以使用一个并发的队列），然后等待该id之前的所有响应全部接收到，再按序返回。 具体实现可以参见nifty中的NiftyDispatcher类。","categories":[],"tags":[]},{"title":"数据库MVCC机制","slug":"数据库MVCC机制","date":"2018-05-07T16:01:33.000Z","updated":"2018-05-07T16:07:26.187Z","comments":true,"path":"2018/05/08/数据库MVCC机制/","link":"","permalink":"http://imwyy.github.io/2018/05/08/数据库MVCC机制/","excerpt":"","text":"https://coolshell.cn/articles/6790.html http://www.cnblogs.com/naci/p/3753644.html InnoDB的MVCC之（乐观锁），是通过在每行记录保存两个隐藏列来实现的，适合对读的响应速度和并发性要求比较高的场景。这两个列，一个是存创建时间，一个是删除时间，这里的时间指的是，系统版本号，并不是真正的时间值。 每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录版本号比较。 下面看一个在REPEATABLE READ（可重复读）隔离级别下，MVCC的具体操作： SELECT：InnoDB会根据以下两个条件检查每行记录： InnoDB只查找版本小于或等于当前事务版本的数据行，这样可以确保事务读取的行，是在事务开始前就已经存在的，或者是事务自身插入或者修改过的数据。 行的删除版本要么未定义，要么大于当前事务的版本。这可以确保事务读取到的行，在事务开始前未被删除。 只有符合上述两个条件的记录，才能返回做为查询结果。 INSERT InnoDB为新插入的每一行保存当前系统版本号作为行版本号。 DELETE InnoDB为删除的每一行保存当前系统版本号作为行删除标识。 UPDATE InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识。 保存这两个额外的系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好。并且也能保证只会读取到符合标准的行。不足之处是每行记录都需要额外的存储空间，需要做更多的检查工作，以及一些额外的维护工作。 MVCC只在REPEATABLE READ（可重复读）和READ COMMITTED（提交读）两个隔离级别下工作。其他两个隔离级别都和MVCC不兼容。READ UNCOMMITTED（未提交读）总是读取最新的数据行，而SERIALIZBLE（可串行化）则会对所有读取的行加锁。 当多个用户/进程/线程同时对数据库进行操作时，会出现3种冲突情形： 读-读，不存在任何问题 读-写，有隔离性问题，可能遇到脏读（会读到未提交的数据） ，幻影读等。 写-写，可能丢失更新要解决冲突 一种办法是是锁，即基于锁的并发控制，比如2PL，这种方式开销比较高，而且无法避免死锁。 多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 这样在读操作不用阻塞写操作，写操作不用阻塞读操作的同时，避免了脏读和不可重复读 乐观并发控制（OCC）是一种用来解决写-写冲突的无锁并发控制，认为事务间争用没有那么多，所以先进行修改，在提交事务前，检查一下事务开始后，有没有新提交改变，如果没有就提交，如果有就放弃并重试。乐观并发控制类似自选锁。乐观并发控制适用于低数据争用，写冲突比较少的环境。 多版本并发控制可以结合基于锁的并发控制来解决写-写冲突，即MVCC+2PL，也可以结合乐观并发控制来解决写-写冲突","categories":[],"tags":[]},{"title":"rxjava+retrofit封装处理网络请求","slug":"rxjava-retrofit封装处理网络请求-1","date":"2018-05-06T15:18:15.000Z","updated":"2018-05-06T15:18:15.375Z","comments":true,"path":"2018/05/06/rxjava-retrofit封装处理网络请求-1/","link":"","permalink":"http://imwyy.github.io/2018/05/06/rxjava-retrofit封装处理网络请求-1/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"rxjava+retrofit封装处理网络请求","slug":"rxjava-retrofit封装处理网络请求","date":"2018-05-06T15:17:43.000Z","updated":"2018-05-06T15:17:43.676Z","comments":true,"path":"2018/05/06/rxjava-retrofit封装处理网络请求/","link":"","permalink":"http://imwyy.github.io/2018/05/06/rxjava-retrofit封装处理网络请求/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"rxjava2+retrofit封装处理网络请求全解析","slug":"rxjava+retrofit封装处理网络请求","date":"2018-05-06T15:17:37.000Z","updated":"2018-05-07T12:57:28.644Z","comments":true,"path":"2018/05/06/rxjava+retrofit封装处理网络请求/","link":"","permalink":"http://imwyy.github.io/2018/05/06/rxjava+retrofit封装处理网络请求/","excerpt":"","text":"使用rxjava2+retrofit处理网络请求，线程的切换变得十分简单，代码也简洁了很多。但是简介的代码就是对可扩展性有着负面的影响，所以要对rxjava2+retrofit进行一定封装，使结构更清晰，可扩展性更强。这里给出一种可行的封装。 以下均以登陆请求为例子。 API地址：http://xxx/user/login Post请求，参数account和password均为String 简单封装 首先定一个retrofit接口：UserService 1234567public interface UserService &#123; @FormUrlEncoded @POST(\"/user/login\") Observable&lt;ResponseBean&lt;UidBean&gt;&gt; login(@Field(\"account\") String account, @Field(\"password\") String password);&#125; 这里`ResponseBean`是一个返回值json对应的实体类，服务器返回的json数据格式为`{code: xxx, message: xxx, data:xxx}`。而`UidBean`是一个data的具体内容，也是个json实体类，具体是什么无关紧要。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 服务器返回值的实体类 * Created by stephen on 2017/9/8. */public class ResponseBean&lt;T&gt; &#123; @SerializedName(\"code\") private int code; @SerializedName(\"message\") private String message; @SerializedName(\"data\") private T data; public ResponseBean(int code, String message) &#123; this.code = code; this.message = message; &#125; public int getCode() &#123; return code; &#125; public String getMessage() &#123; return message; &#125; public T getData() &#123; return data; &#125; /** * 根据返回码确定API是否请求返回失败 * * @return 失败返回true, 成功返回false */ public boolean isCodeValid() &#123; return code == 0; &#125; @Override public String toString() &#123; return \"code:\" + code + \", message:\" + message + \",data:\" + data.toString(); &#125;&#125; Oberser类的封装 这里BaseObserver里直接对Disposable进行处理，内存泄漏什么的省心多了。同时还保存了一个子类可见的errMsg，可以获取自定义的错误类型。 （关于Disposable可以参考我的这篇文章，如果有哪里理解错了记得帮忙指出哦）。 12345678910111213141516171819202122232425262728293031323334353637383940414243public abstract class BaseObserver&lt;T&gt; implements Observer&lt;T&gt; &#123; protected String errMsg = \"\"; private Disposable disposable; @Override public void onSubscribe(Disposable d) &#123; disposable = d; &#125; @Override public void onNext(T t) &#123;&#125; @Override public void onError(Throwable e) &#123; LogUtils.e(\"Observer.java\", e.getMessage() + \" \" + toastErrHint); if (!NetworkUtils.isConnected()) &#123; errMsg = \"网络连接出错,\"; &#125; else if (e instanceof HttpException) &#123; errMsg = \"网络请求出错,\"; &#125; else if (e instanceof IOException) &#123; errMsg = \"网络出错,\"; &#125; disposeIt(); &#125; @Override public void onComplete() &#123; disposeIt(); &#125; /** * 销毁disposable */ private void disposeIt() &#123; if (disposable != null &amp;&amp; !disposable.isDisposed()) &#123; disposable.dispose(); disposable = null; &#125; &#125;&#125; 接口类整合retrofit HttpFactory类里是一些网络交互的基本设置，单独放一个类是为了方便扩展。之后就会发现这样做的好处。 12345678910111213141516171819202122232425262728public class HttpFactory &#123; private static HttpFactory instance; public synchronized static HttpFactory getInstance() &#123; return instance == null ? instance = new HttpFactory() : instance; &#125; private Retrofit mRetrofit; private HttpFactory() &#123; //创建一个OkHttpClient并设置超时时间 OkHttpClient httpClient = new OkHttpClient.Builder() .connectTimeout(AppConfig.DEFAULT_TIMEOUT, TimeUnit.SECONDS) .cookieJar(cookieJar) .build(); mRetrofit = new Retrofit.Builder() .client(httpClient) .baseUrl(AppConfig.URL_BASE) .addConverterFactory(GsonConverterFactory.create()) .addCallAdapterFactory(RxJava2CallAdapterFactory.create()) .build(); &#125; Retrofit getmRetrofit() &#123; return mRetrofit; &#125;&#125; - `UserApi`类将retrofit接口封装成rxjava调用的方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 public class APIUser extends BaseAPI &#123; private static final APIUser INSTANCE = new APIUser(); public static APIUser getInstance() &#123; return INSTANCE; &#125; private UserService userService; private Retrofit mRetrofit; private APIUser() &#123; mRetrofit = HttpFactory.getInstance().getmRetrofit(); userService = mRetrofit.create(UserService.class); &#125; /** * 登录 这里为了方便逻辑展示，password直接明文传输 * * @param account 账号 * @param password 密码 * @param observer 观察者 */ public void login(String account, String password, BaseObserver&lt;UidBean&gt; observer) &#123; userService.login(account, password) .subscribeOn(Schedulers.io()) .observeOn(Schedulers.computation()) .map(new Function&lt;ResponseBean&lt;UidBean&gt;, UidBean&gt;() &#123; @Override public UidBean apply(ResponseBean&lt;UidBean&gt; responseBean) throws Exception &#123; return responseBean.getData(); &#125; &#125;) .observeOn(AndroidSchedulers.mainThread()) .subscribe(observer); &#125; &#125; ``` 4. **愉快的调用** ```java APIUser.getInstance().login(account, password, new BaseObserver&lt;UidBean&gt;() &#123; @Override public void onNext(UidBean uidBean) &#123; // your logic code here ToastUtils.showShort(\"登录成功\"); &#125; &#125;); 添加cookie支持以上实现了一个简单的封装，现在我们开始加入cookie支持：第一次拿到set-cookie的时候保存cookie，然后再每次request的时候加入cookie。 这里借用了一下GitHub上别人造的轮子，使用了PersistentCookieJar。PersistentCookieJar是ClearableCookieJar的一个具体实现，利用SharedPreferences保存cookie。具体使用方法如下： 添加gradle依赖 在HttpFactory添加cookieJar 1234567891011121314151617181920212223242526272829303132333435363738public class HttpFactory &#123; private static HttpFactory instance; public synchronized static HttpFactory getInstance() &#123; return instance == null ? instance = new HttpFactory() : instance; &#125; private Retrofit mRetrofit; private ClearableCookieJar cookieJar; private HttpFactory() &#123; //设置cookie cookieJar = new PersistentCookieJar(new SetCookieCache(), new SharedPrefsCookiePersistor()); //创建一个OkHttpClient并设置超时时间 OkHttpClient httpClient = new OkHttpClient.Builder() .connectTimeout(AppConfig.DEFAULT_TIMEOUT, TimeUnit.SECONDS) .cookieJar(cookieJar) .build(); mRetrofit = new Retrofit.Builder() .client(httpClient) .baseUrl(AppConfig.URL_BASE) .addConverterFactory(GsonConverterFactory.create()) .addCallAdapterFactory(RxJava2CallAdapterFactory.create()) .build(); &#125; Retrofit getmRetrofit() &#123; return mRetrofit; &#125; /** * 退出登录后清除cookie */ public void clearCookie() &#123; cookieJar.clear(); &#125;&#125; 这里HttpFactory还提供了一个对外接口，可以在退出登录后调用清除clearCookie()cookie。 现在每次处理请求的时候，ClearableCookieJar就会帮你打点好所有的cookie验证相关信息。 添加错误码统一处理很多时候服务器返回的json数据格式会有一个统一的格式，比如以上说的形式：{code: xxx, message: xxx, data:xxx}。带有返回状态码和错误信息，如果对于每个code我们都在Observer中的onNext处理，显然很麻烦很冗余一点也不优雅，可扩展性也很差。比如服务器新添加一个状态码，所有的代码都要改，不切实际嘛。所以我们下面要做的就是对错误码添加统一处理。 实现思路：对于json数据response的时候，我们都会用GsonConverterFactory来将json转换为java对象，那么我们就可以利用GsonConverterFactory来统一处理。我们来重新定义一个类实现GsonConverterFactory的关键方法。因为GsonConverterFactory是final的，不可继承，所以这里会重新定义三个类：CustomGsonConverterFactory，CustomGsonResponseBodyConverter和CustomGsonRequestBodyConverter分别对应默认的GsonConverterFactory，GsonResponseBodyConverter和GsonRequestBodyConverter。 CustomGsonConverterFactory 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667 /** * 自定义的GsonConverterFactory * 主要是重写了responseBodyConverter类 * Created by stephen on 2017/10/2. */ public final class CustomGsonConverterFactory extends Converter.Factory &#123; /** * Create an instance using a default &#123;@link Gson&#125; instance for conversion. Encoding to JSON and * decoding from JSON (when no charset is specified by a header) will use UTF-8. */ public static CustomGsonConverterFactory create() &#123; return create(new Gson()); &#125; /** * Create an instance using &#123;@code gson&#125; for conversion. Encoding to JSON and * decoding from JSON (when no charset is specified by a header) will use UTF-8. */ public static CustomGsonConverterFactory create(Gson gson) &#123; return new CustomGsonConverterFactory(gson); &#125; private final Gson gson; private CustomGsonConverterFactory(Gson gson) &#123; if (gson == null) throw new NullPointerException(\"gson == null\"); this.gson = gson; &#125; @Override public Converter&lt;ResponseBody, ?&gt; responseBodyConverter(Type type, Annotation[] annotations, Retrofit retrofit) &#123; TypeAdapter&lt;?&gt; adapter = gson.getAdapter(TypeToken.get(type)); return new CustomGsonResponseBodyConverter&lt;&gt;(gson, adapter); &#125; @Override public Converter&lt;?, RequestBody&gt; requestBodyConverter(Type type, Annotation[] parameterAnnotations, Annotation[] methodAnnotations, Retrofit retrofit) &#123; TypeAdapter&lt;?&gt; adapter = gson.getAdapter(TypeToken.get(type)); return new CustomGsonRequestBodyConverter&lt;&gt;(gson, adapter); &#125; &#125; ``` - CustomGsonRequestBodyConverter。这个类没有改动，直接copy了GsonRequestBodyConverter的源码。 ```java final class CustomGsonRequestBodyConverter&lt;T&gt; implements Converter&lt;T, RequestBody&gt; &#123; private static final MediaType MEDIA_TYPE = MediaType.parse(\"application/json; charset=UTF-8\"); private static final Charset UTF_8 = Charset.forName(\"UTF-8\"); private final Gson gson; private final TypeAdapter&lt;T&gt; adapter; CustomGsonRequestBodyConverter(Gson gson, TypeAdapter&lt;T&gt; adapter) &#123; this.gson = gson; this.adapter = adapter; &#125; @Override public RequestBody convert(T value) throws IOException &#123; Buffer buffer = new Buffer(); Writer writer = new OutputStreamWriter(buffer.outputStream(), UTF_8); JsonWriter jsonWriter = gson.newJsonWriter(writer); adapter.write(jsonWriter, value); jsonWriter.close(); return RequestBody.create(MEDIA_TYPE, buffer.readByteString()); &#125; &#125; CustomGsonResponseBodyConverter。重信写convert方法。这里直接将返回值转换为responseBean，并根据返回值判断是否返回成功（这里根据responseBean.isCodeValid()判断）。如果返回不成功，可以自定义一些exception，并抛出异常。比如我这里的throw new APIException。 123456789101112131415161718192021222324252627282930313233final class CustomGsonResponseBodyConverter&lt;T&gt; implements Converter&lt;ResponseBody, T&gt; &#123; private final Gson gson; private final TypeAdapter&lt;T&gt; adapter; private static final Charset UTF_8 = Charset.forName(\"UTF-8\"); CustomGsonResponseBodyConverter(Gson gson, TypeAdapter&lt;T&gt; adapter) &#123; this.gson = gson; this.adapter = adapter; &#125; @Override public T convert(ResponseBody value) throws IOException &#123; String response = value.string(); //关键代码 ResponseBean responseBean = gson.fromJson(response, ResponseBean.class); if (!responseBean.isCodeValid()) &#123; value.close(); throw new APIException(responseBean.getCode(), responseBean.getMessage()); &#125; MediaType contentType = value.contentType(); Charset charset = contentType != null ? contentType.charset(UTF_8) : UTF_8; InputStream inputStream = new ByteArrayInputStream(response.getBytes()); Reader reader = new InputStreamReader(inputStream, charset); JsonReader jsonReader = gson.newJsonReader(reader); try &#123; return adapter.read(jsonReader); &#125; finally &#123; value.close(); &#125; &#125;&#125; 同样的自定义的exception可以在BaseObserver的onError中捕获然后获取不同的errMsg。 123456789101112131415@Overridepublic void onError(Throwable e) &#123; LogUtils.e(\"Observer.java\", e.getMessage() + \" \" + toastErrHint); if (!NetworkUtils.isConnected()) &#123; errMsg = \"网络连接出错,\"; &#125; else if (e instanceof APIException) &#123; APIException exception = (APIException) e; errMsg = exception.getMessage(); &#125; else if (e instanceof HttpException) &#123; errMsg = \"网络请求出错,\"; &#125; else if (e instanceof IOException) &#123; errMsg = \"网络出错,\"; &#125;&#125; 总结好了至此，封装已经可以达到了一定的可扩展性，使用也很方便。事实上你还可以在BaseObserver中添加一些其他的东西，比如加载动画等等。 大家有意见提出来一起探讨，共同进步。:）","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"}]},{"title":"java并发编程之DCL单例模式与Happen-Before","slug":"java并发编程之DCL单例模式缺陷","date":"2018-05-05T12:47:56.000Z","updated":"2018-05-05T13:06:13.291Z","comments":true,"path":"2018/05/05/java并发编程之DCL单例模式缺陷/","link":"","permalink":"http://imwyy.github.io/2018/05/05/java并发编程之DCL单例模式缺陷/","excerpt":"","text":"本来想写一篇文章说说DCL的缺陷顺带说一下JMM，看到有一篇文章写的不错，就直接转过来修改了一下。原文出处在这里。 1 前言单例模式是我们经常使用的一种模式，一般来说很多资料都建议我们写成如下的模式： 1234567891011121314151617181920212223242526public class Instance &#123; private String str = \"\"; private int a = 0; private static Instance ins = null; /** * 构造方法私有化 */ private Instance()&#123; str = \"hello\"; a = 20; &#125; /** * DCL方式获取单例 * @return */ public static Instance getInstance()&#123; if (ins == null)&#123; synchronized (Instance.class)&#123; ins = new Instance(); &#125; &#125; return ins; &#125;&#125; 但是这种方式其实是有缺陷的，具体什么缺陷呢？我们首先要了解JVM了内存模型，请看下面分析 2 JVM内存模型JVM模型如下图： 这里着重介绍下VM Stack,其他的我相信都比较熟悉。VM Stack是线程私有的区域。他是java方法执行时的字典：它里面记录了局部变量表、 操作数栈、 动态链接、 方法出口等信息。 在《java虚拟机规范》一书中对这部分的描述如下： 栈帧是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接、方法返回值和异常分派。 栈帧随着方法调用而创建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算作方法结束。栈帧的存储空间分配在 Java 虚拟机栈之中，每一个栈帧都有自己的局部变量表、操作数栈和指向当前方法所属的类的运行时常量池的引用。 java中某个线程在访问堆中的线程共享变量时，为了加快访问速度，提升效率，会把该变量临时拷贝一份到自己的VM Stack中，并保持和堆中数据的同步。 3 传统DCL方式的缺陷有了以上的基础知识我们就可以知道DCL方式的缺陷在哪儿了。 当线程A在获取了Instance.class锁时，对ins进行 ins = new Instance() 初始化时，由于这是很多条指令，jvm可能会乱序执行。这个时候如果线程B在执行if (ins == null)时，正常情况下，如果为true，说明需要获取Instance.class锁，等待初始化。但是这时候，假设线程A再没有对ins进行初始化完，比如只对str进行了赋值，还没有来的及对a进行赋值，假如jvm将未完成赋值的值拷贝回堆中，这个时候线程B有可能读到的值就不是为null了，就会造成数据丢失的情况。这时候我们发现线程B获取的对象中a的值是0，而不是20。 总结起来：对ins的写操作不 happen-before 对它的读操作 这就是DCL方式的缺陷，那么怎么避免呢？ 4 happen-before原则JMM为程序中所有的操作定义了一个偏序关系，成为Happen-Before。要想保证执行操作B的线程看到线程A的结果，那么A和B之间必须满足Happen-Before规则。 当一个变量被多个线程读取并且至少被一个线程写入时，如果在读操作和写操作之间没有依照Happen-Before来排序，那么就会产生数据竞争的问题。 具体来说，happen-before规则包括： 程序顺序规则：如果程序中操作A在操作B之前，那么B操作可以看到A操作的所有内存改变。 监视器锁规则：如果线程1解锁了monitor A，接着线程2锁定了A，那么，线程1解锁A之前的写操作都对线程2可见（线程1和线程2可以是同一个线程）。 volatile变量规则：如果线程1写入了volatile变量V，接着线程2读取了V，那么，线程1写入V及之前的写操作都对线程2可见（线程1和线程2可以是同一个线程） 线程启动规则：在线程上对Thread.start的调用必须在该线程中执行任何操作之前执行。 线程结束规则：线程中的任何操作都必须在其他线程检测到线程A已经结束（或者从Thread.join中成功返回，或者在调用Thread.isAlive时返回false）之前执行完成。 中断规则：当一个线程在另一个线程上调用interrupt时，必须在被中断线程检测到interrupt调用之前执行（通过抛出InterruptedException，或者调用isInterrupted和interrupted）。 终结器规则：对象的构造函数必须在启动该对象的终结器之前执行完成。 传递性：如果操作A在操作B之前执行，并且操作B在操作C之前执行，那么操作A必须在操作C之前执行。 4 单例模式的正确写法有了以上的分析我们知道，我们只需要在保证对ins的访问是读在写之后即可，因此正确的做法是在ins 前加上一个关键字volatile。因此DCL的正确写法应该如下： 1234567891011121314151617181920212223242526public class Instance &#123; private String str = \"\"; private int a = 0; private volatile static Instance ins = null; /** * 构造方法私有化 */ private Instance()&#123; str = \"hello\"; a = 20; &#125; /** * DCL方式获取单例 * @return */ public static Instance getInstance()&#123; if (ins == null)&#123; synchronized (Instance.class)&#123; ins = new Instance(); &#125; &#125; return ins; &#125;&#125;","categories":[{"name":"并发","slug":"并发","permalink":"http://imwyy.github.io/categories/并发/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://imwyy.github.io/tags/并发/"}]},{"title":"java并发编程之原子变量和CAS","slug":"java并发编程之原子变量和CAS","date":"2018-05-05T05:48:54.000Z","updated":"2018-05-05T12:41:46.116Z","comments":true,"path":"2018/05/05/java并发编程之原子变量和CAS/","link":"","permalink":"http://imwyy.github.io/2018/05/05/java并发编程之原子变量和CAS/","excerpt":"","text":"我们知道锁的实现可以分为乐观锁和悲观锁，具体可以参照我的这篇文章数据库的锁机制及原理。java中也有对应的乐观锁和悲观锁的实现，在之前的文章中我们讨论了ReentrantLock和synchronized，它们都是悲观锁的具体实现，都是先确保拿了锁才会去操作。java中同样也有乐观锁的实现，这就是CAS（compareAndSwap）机制。 锁的劣势 如果锁已经被占用，那么其他线程必须被挂起。当线程恢复执行的时候，必须等待其他线程执行完它们的时间片，才能被调度执行。在挂起和恢复线程等过程中存在着很大的开销。 当一个线程正在等待锁时，它不能做任何其他事情。如果一个线程在持有锁的情况下被延迟执行（比如发生缺页错误、调度延迟），那么所有需要这个锁的线程都将无法执行下去。而且会发生优先级反转，即优先级高的线程仍然需要等待，导致它的优先级降低。 CAS实现CAS是一种乐观锁的实现，需要接触冲突检查机制来判断在更新过程中是否存在其他线程的干扰。如果存在，那么这个操作将失败，并且可以重试。具体来讲，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 12345int A;do &#123; A = value.get();&#125; while (V != value.compareAndSwap(A,B)); CAS的问题 ABA问题。 ABA是一种异常现象，出现异常的点在于，每次去比较内存值V和旧的预期值A是否相等，如果相等我们就判定了在此之前V的值没有改变，但事实并不是这样，很有可能V的值经历了A-B-A的变化而我们没有觉察到。 对于ABA问题有一个相对简单的解决方案：不是更新某个引用的值，而是更新两个值，包括一个引用和一个版本号。即使这个值由A变为B，然后又变为A，版本号也是不同的。java中AtomicStampedReference和AtomicMarkableReference支持在两个变量上执行原子的条件更新，实现版本号控制。 活锁问题。循环等待时间开销大 所谓活锁，就是线程一直处于running的状态然而却在做无用功，比如while循环在尝试更新，然而每次重试都是失败的，导致线程的其他任务得不到执行。 对于活锁问题的解决可以在重试机制中引入一定的随机量。 原子变量java中AtomicInteger等等原子类型就是利用了CAS实现。看源码。 12345678/** * Atomically increments by one the current value. * * @return the previous value */public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1);&#125; 再看unsafe.getAndAddInt 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 果然实现的代码和我们之前的模版一致。 我们再来看原子变量和一般锁的性能比较。在中低程度的竞争下，原子变量能够提供更高的可伸缩性，而在高强度的竞争下，锁能够有效的避免竞争。（摘自《java并发编程实战》Page-269） 可伸缩性是指，当增加计算资源时（例如CPU，内存、存储容量或IO带宽），程序的吞吐量或者处理能力能相应的增加。 这里有一个特别需要注意的点：原子的标量类并没有扩展基本的包装类，例如Integer。基本类型的包装类是不可修改的，而原子变量是可修改的。在原子变量中同样没有重新定义hashcode和equals方法，每个实例都是不同的，所以它们也不能用来做基于散列的容器中的键值。","categories":[],"tags":[]},{"title":"你真的会二分查找吗？","slug":"你真的会二分查找吗？","date":"2018-05-05T02:50:19.000Z","updated":"2018-05-05T05:18:04.819Z","comments":true,"path":"2018/05/05/你真的会二分查找吗？/","link":"","permalink":"http://imwyy.github.io/2018/05/05/你真的会二分查找吗？/","excerpt":"","text":"写这篇文章的初衷是因为leetcode遇到了一个坑。我们先一起来看看。 leetcode 34Given an array of integers nums sorted in ascending order, find the starting and ending position of a given target value. Your algorithm’s runtime complexity must be in the order of O(log n). If the target is not found in the array, return [-1, -1]. Example 1:Input: nums = [5,7,7,8,8,10], target = 8Output: [3,4] Example 2:Input: nums = [5,7,7,8,8,10], target = 6Output: [-1,-1] 代码要求算法复杂度为O(log n)。很显然，肯定是二分查找。二分查找到target然后在两边扩展找边界呗。 1234567891011121314151617181920212223242526public int[] searchRange(int[] nums, int target) &#123; if (nums.length == 0) return new int[]&#123;-1, -1&#125;; int left = 0, right = nums.length - 1, mid; while (left &lt; right) &#123; mid = (left + right)/ 2; if (nums[mid] &lt; target) &#123; left = mid; &#125; else if (nums[mid] &gt; target)&#123; right = mid; &#125; else &#123; left = mid; right = mid; break; &#125; &#125; if (nums[left] != target) &#123; return new int[]&#123;-1, -1&#125;; &#125; else &#123; while (left - 1 &gt;= 0 &amp;&amp; nums[left - 1] == target) left--; while (right + 1 &lt; nums.length &amp;&amp; nums[right + 1] == target) right++; return new int[]&#123;left, right&#125;; &#125;&#125; 然后拿个测试[5, 7, 7, 8, 8, 10]， target6 用例跑一下。WTF？死循环？？ 问题在哪？很困惑，之前一直这么写，没出过问题，怎么会死循环。那我就跟着代码走一遍看看。 数组[5, 7, 7, 8, 8, 10]， target 6 left right mid 0 5 2 0 2 1 0 1 0 0 1 0 0 1 0 找到了问题。left=0，right=1， mid=0的时候，nums[left]=5, nums[right]=7,nums[mid]=5在如下代码里，会一直执行if的第一个分支，三个值都不会改变。 12345if (nums[mid] &lt;= target) &#123; left = mid;&#125; else &#123; right = mid;&#125; 而left = mid;才是罪魁祸首，如果这么写了，一旦target元素不在数组，那么就是死循环。所以应该改成left = mid + 1;。这样就顺利通过test case。总结起来，这个错误更是因为自己的疏忽。 还可能有什么问题？ mid的选取 代码中我写的是mid = (left + right)/ 2;，但其实是有问题的，问题在于如果left和right都很大，那么两者相加是很可能溢出的。所以最好的写法应该是mid = left + (right - left)/ 2; left和right怎么跳? 这问题也是我最初出现死循环的原因。我把left = mid改成了left = mid + 1，为什么不把right = mid也改成right = mid - 1呢。在这里当然也是可以的，因为我只是想在数组里找到一个等于target的值的下标。 验证一下我的结论，我们来看一下jdk里面对于二分查找的实现。在Arrays这个类里面。 12345678910111213141516// Like public version, but without range checks.private static int binarySearch0(int[] a, int fromIndex, int toIndex, int key) &#123; int low = fromIndex; int high = toIndex - 1; while (low &lt;= high) &#123; int mid = (low + high) &gt;&gt;&gt; 1; int midVal = a[mid]; if (midVal &lt; key) low = mid + 1; else if (midVal &gt; key) high = mid - 1; else return mid; // key found &#125; 没错这里确实是，low = mid + 1和high = mid - 1。但是前面mid的选取好像和我说的有点冲突。 int mid = (low + high) &gt;&gt;&gt; 1。这里&gt;&gt;&gt;是指无符号右移，高位补0，而这里的low、high都是非负数，用这个应该只是一个防御性的编程。 （计算机移位操作的效率要高很多，jdk里面很多用到了移位，如ArrayList、HashMap等等） low和high直接相加，难道jdk没有考虑溢出的情况吗？其实不是，Java里数组的长度是有限制的，这个限制具体是由jvm可配置的（？）,我查看源码没有找到具体值是多少，至少当我执行int[] test = new int[Integer.MAX_VALUE/2];的时候，会报OutOfMemoryError错。既然这样也就不用考虑溢出问题，直接用移位操作反而更快。 更多情况上面讨论的都是标准的二分查找，也就是在一个数组里找一个数的下标，找不到返回负数。其实还会经常遇到另一种，就是找到第一次出现该数的下标，或者最后一次出现该数的下标。显然jdk里的binarySearch并不能实现这个要求，java doc里面也有明说 Searches the specified array of ints for the specified value using thebinary search algorithm. If the array contains multiple elements with the specified value, there is no guarantee which one will be found. 对于”查找第一次出现该数的下标”，我们可以理解成二分查找就是left不断往后走，找到目标位置的过程（最终结果肯定是left的值）。所以为了不出错，我们最好每次移动只改变left。 而对于“查找最后一次出现该数的下标”可以看作是“查找第一次出现该数的下标“的镜像，可以理解为后从往前进行二分查找（把数组反转就是求解第一种情况了），所以在mid选取的时候，要反一反mid = right - ((right-left)&gt;&gt; 1) 看到很多地方的写法都是mid = left + ((right-left + 1)&gt;&gt; 1);，这样反而不好理解。写成mid = right - ((right-left)&gt;&gt; 1)就好理解多了。 二分查找第一次出现该数的下标 1234567891011while (left &lt; right) &#123; mid = left + ((right-left)&gt;&gt; 1); if (nums[mid] &lt; target) &#123; // 如果中间值比target小，left移到mid+1 left = mid + 1; &#125; else &#123; // 如果中间值不比target小即可能等于，right移到mid right = mid; &#125; &#125; 二分查找最后一次出现该数的下标 1234567891011while (left &lt; right) &#123; mid = right - ((right-left)&gt;&gt; 1);//注意这里！！ if (nums[mid] &lt;= target) &#123; // 如果中间值小于等于target即不比target大，left移到mid 因为left的目标是和target相等的最后一个下标 left = mid; &#125; else &#123; // 如果中间值比target大，right移到mid-1 right = mid -1 ; &#125; &#125; 完善仔细看看自己的解法，最后那个while循环有点问题，如果这个范围很大，那岂不是要循环整个数组了？ 所以有了前面的铺垫，这个题目可以用更快更清晰的方法解决。分别找到target的第一次和最后一次出现的位置即可。最后附上代码 12345678910111213141516171819202122232425262728293031323334public int[] searchRange(int[] nums, int target) &#123; if (nums.length == 0) return new int[]&#123;-1, -1&#125;; int left = 0, right = nums.length - 1, first; //找到第一次出现的位置 while (left &lt; right) &#123; int mid = left + ((right - left) &gt;&gt; 1); if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else &#123; right = mid; &#125; &#125; if (nums[left] != target) &#123; return new int[]&#123;-1, -1&#125;; &#125; first = left; left = 0; right = nums.length - 1; //找到最后一次出现的位置 while (left &lt; right) &#123; int mid = right - ((right - left) &gt;&gt; 1); if (nums[mid] &lt;= target) &#123; left = mid; &#125; else &#123; right = mid - 1; &#125; &#125; return new int[]&#123;first, left&#125;;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://imwyy.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://imwyy.github.io/tags/算法/"}]},{"title":"java并发编程之ReentrantLock和synchronized","slug":"java并发编程之lock和synchronize","date":"2018-05-04T13:13:48.000Z","updated":"2018-05-04T16:21:23.392Z","comments":true,"path":"2018/05/04/java并发编程之lock和synchronize/","link":"","permalink":"http://imwyy.github.io/2018/05/04/java并发编程之lock和synchronize/","excerpt":"","text":"在jdk5之前，协调共享对象访问的只有synchronized和lock，jdk增加了一种新的锁机制：ReentrantLock。lock并不是对内置锁的替换，而是互补。这篇文章主要循序渐进的比较两者异同和适用场景，如果有理解错的地方希望大家能指出。 synchronized怎么实现的？synchronized是Java中解决并发问题的一种最常用最简单的一种方法，有效满足了线程安全的三大要求：原子性、可见性和有序性。 synchronized可以用在三个地方： 修饰普通方法。锁的是实例对象。 修饰静态方法。锁的是类。 修饰代码块。锁的是括号内的对象。 synchronized是依靠对象头中一个monitor（监视器锁）。执行synchronized修饰的方法或者代码块的时候，会首先去尝试获取这个monitor，如果monitor获取成功，那么就可以执行。否则就必须等待，一直到可以获取monitor。synchronized的可重入性也就好解释了，如果一个线程已经获取monitor，再次获取会将计数器加一，而不用再去等待锁。退出的时候计数器会减1，当减到0的时候，就可以唤醒其他等待的线程。当然这些实现JVM都已经帮我们打理好了，所以我们会觉得synchronized用起来非常简单。 为什么要用ReentrantLock？前面介绍了synchronized，使用方便简单。所谓成也萧何败也萧何，太简单了就会有一些问题： 无法中断一个已经正在等待获取锁的线程。如果一个线程一直没法获取锁，就会一直等待下去。ReentrantLock可以使用中断和定时锁，等待一定时间如果没有获取就返回。 无法对加锁规则进行改动，无法实现非阻塞结构的加锁规则。 synchronized如果遇到死锁问题，恢复的解决方案就是重新启动程序。 很多场景，读与读并不需要互斥，而synchronized粗暴的将所有操作都互斥。ReadWriteLock可以实现读-写锁，使用两个Lock对象，一个负责读一个负责写。 synchronized是非公平锁，无法适应需要公平锁的场景。ReentrantLock分为公平锁和非公平锁。 所谓公平锁就是每次唤醒的时候，按照FCFS原则唤醒等待队列中的线程。而非公平锁是唤醒的时候，其他等待的线程一起去抢锁，后来的线程可能比先到的线程要先拿到锁，可以插队，这也就是非公平的体现。 在激烈竞争的情况下，非公平锁的性能高于公平性，是因为插队可以带来吞吐量的提升。举例来说，线程A持有锁，线程B在等待锁。此时线程A是释放锁，B将被唤醒，然后尝试获取锁。此时线程C很可能在C没有被完全唤醒之前获取这个锁，锁被更早的获得了，当然也就提高了吞吐量。 相对应的ReentrantLock的特点就是： 可中断，可定时，缓解了死锁的问题。 公平锁，可以实现线程先来的先获取锁 可以有ReadWriteLock实现读写锁，读与读不必互斥。 总结一句就是，synchronized不够灵活，这也是ReentrantLock出现的原因。一个很好的例子就是锁分段技术，比如在ConcurrentHashMap中是划分segment来将锁分段，提高并发环境下的性能，而源码中就是用的ReenterantLock。 123456789/** * Stripped-down version of helper class used in previous version, * declared for the sake of serialization compatibility */static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; final float loadFactor; Segment(float lf) &#123; this.loadFactor = lf; &#125;&#125; 什么时候用ReentrantLock，什么时候用synchronized？ReentrantLock带来了使用的灵活性的代价就是，你需要仔细负责lock的操作，比如unlock，加锁就有释放，用起来自然就没有synchronized那么省心。 synchronized在java6有了一些升级，所以两者的性能事实上差距不大。所以私以为，如果需要对锁操作或者等待队列有着更高的灵活性或者需要锁是公平的，使用ReentrantLock。否则使用synchronized足矣。","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java并发","slug":"java并发","permalink":"http://imwyy.github.io/tags/java并发/"}]},{"title":"java并发编程之对象组合","slug":"java并发编程之对象组合","date":"2018-05-04T13:12:03.000Z","updated":"2018-05-04T13:12:15.543Z","comments":true,"path":"2018/05/04/java并发编程之对象组合/","link":"","permalink":"http://imwyy.github.io/2018/05/04/java并发编程之对象组合/","excerpt":"","text":"介绍可以通过对象组合构造一个满足需求的线程安全的类。笔记来自《java并发编程实战》 监视器模式（实例封闭）遵循java监视器模式的对象会把对象的所有可变状态都封装起来，并由对象自己的内置锁来保护。如： 12345678910public calss PrivateLock &#123; private final Object myLock = new Object(); Widget widget; void someMethod() &#123; synchronized(myLock) &#123; //do something with widget &#125; &#125;&#125; 线程安全性委托所谓线程安全性的委托，就是如果类的成员变量都是线程安全的，整个类的线程安全性可以委托给类的成员变量。当然至于委托后，这个对象是不是线程安全的，要“看情况而定”。 当成员变量之间没有任何交互或者不变形条件约束的时候，那么这个类可以表现为线程安全。如： 1234567public class VisualComponet&#123; private final List&lt;Listener&gt; list = new CopyOnWriteArrayList&lt;Listener&gt;(); public void addListener(Listener listener) &#123; list.add(listener); &#125;&#125; 当状态变量之间存在着某些不变型条件的时候，委托失效，即类不是线程安全的。如： 1234567891011public class NumberRange &#123; //不变性条件为 lower &lt; upper private final AtomicInteger lower = new AtomicInteger(0); private final AtomicInteger upper = new AtomicInteger(0); public void setLower(int i) &#123; if (i &lt;= upper.get()) &#123; lower.set(i); &#125; &#125;&#125; 在`setLower`方法中，先检查再赋值，并不是原子性的，当然也会出现线程安全性的问题。 在现有线程安全类中添加功能java类库中有许多有用的基础模块，应该优先选择重用这些现有的类而不是创建新的类。 继承线程安全的类，实现一些附加的操作，如继承vector来“实现不存在就添加”的操作： 1234567public class BetterVector extends Vector &#123; public synchronized boolean putIfAbsent(Object o) &#123; boolean absent = ! contains(o); if (absent) add(x) return absent; &#125;&#125; 利用Collections.synchronizedList()实现 1234567891011public class ListHelper &#123; public List&lt;E&gt; list = new Collections.synchronizedList(new ArrayList&lt;&gt;); public boolean putIfAbsent(Object o) &#123; synchronized(list) &#123; boolean absent = ! contains(o); if (absent) add(x) return absent; &#125; &#125;&#125; 这里有个要注意的，putIfAbsent获取的锁是list的锁，如果简单粗暴的在putIfAbsent上加上synchronized，是有问题的，像这样 12345678910@NotThreadSafe class BadListHelper &lt;E&gt; &#123; public List&lt;E&gt; list = Collections.synchronizedList(new ArrayList&lt;E&gt;()); public synchronized boolean putIfAbsent(E x) &#123; boolean absent = !list.contains(x); if (absent) list.add(x); return absent; &#125; &#125; 这里的问题就是，synchronized所对应的锁和对list操作的锁不是同一把，你获取了BadListHelper的锁，但是没有获取list的锁，线程安全问题还是没有解决，别人还是可以在你执行putIfAbsent方法时，对list进行修改。 使用组合对象 123456789101112131415public class ImprovedList&lt;E&gt; implements List&lt;E&gt; &#123; private final List&lt;E&gt; list; public ImprovedList(List&lt;E&gt; list) &#123; this.list = list; &#125; public synchronized boolean putIfAbsent(Object o) &#123; boolean absent = ! contains(o); if (absent) add(x) return absent; &#125; ...&#125; 这里涉及到了Collections.synchronizedList()和CopyOnWriteArrayList。关于这两个，看看源码研究研究区别，专门写篇博客。","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java并发","slug":"java并发","permalink":"http://imwyy.github.io/tags/java并发/"}]},{"title":"java并发编程之线程安全性和对象共享","slug":"java并发编程之线程安全性和对象共享","date":"2018-05-04T13:10:32.000Z","updated":"2018-05-04T13:11:33.612Z","comments":true,"path":"2018/05/04/java并发编程之线程安全性和对象共享/","link":"","permalink":"http://imwyy.github.io/2018/05/04/java并发编程之线程安全性和对象共享/","excerpt":"","text":"读书笔记来自《java并发编程实战》。 线程安全性可重入锁 可重入意味着获取锁的操作的粒度是线程而不是调用。 实现方法是为每个锁关联一个获取计数值和一个所有者进程。当计数器为0，这个锁被认为可以被任何线程池游。当线程请求一个未被池游的锁时，JVM将记下锁的持有者，并且将计数器置为1，如果同一个线程再次获取这个锁，计数器将递增。当线程退出痛不快，计数器递减。当计数器为0，锁被释放。 对象的共享可见性volatile关键字并发需要三点必须满足的特性 原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 可见性：多个线程访问一个变量，其他线程能看到变量的改变 有序性：即程序执行的顺序按照代码的先后顺序执行。 volatile满足了可见性和有序性，没有办法满足原子性。实现原理是，每个线程的工作内存中，复制了变量的值（源自cpu缓存，防止每次都去主存获取）。当某个线程更改变量的值，其他线程的缓存失效，必须去主存重新获取。更改完成立马写回主存。 所以使用volatile的场景是能够保证操作原子性的情况变量的更改不依赖于当前值，或者可以确保只有单个线程更新变量的值。 加锁可以保证可见性加锁不仅局限于互斥行为，还包括了内存可见性。 发布和逸出this引用逸出1234567891011public class ThisEscape&#123; public ThisEscape (EventSource source)&#123; source.registerListener&#123; new EventListener()&#123; public void onEvent(Event e)&#123; doSomething(e); &#125; &#125; &#125;; &#125;&#125; 在对象没有确定完全初始化之前就发布了this引用。在构造函数中注册了监听事件，但是此时ThisEscape对象还没有完全初始化。 安全的对象构造过程1234567891011121314151617public class SafeListener&#123; private final EventListener listener; private SafeListener()&#123; listener =new EventListener()&#123; public void onEvent(Event e)&#123; doSomething(e); &#125; &#125;; &#125; public static SafeListener newInstance(EventSource source)&#123; SafeListener safe=new SafeListener(); source.registerListener(safe.listener); return safe; &#125;&#125; 在执行source.registerListener(safe.listener);之前， SafeListener已经完全初始化。 线程封闭Ad-hoc线程封闭完全由程序控制维护线程的封闭性，十分脆弱，尽量要少用。 栈封闭即使用的变量均为局部变量，每次调用方法都会把局部变量压栈，同样也不存在线程安全的问题。 但是注意不可以对传入的引用做修改（函数副作用）或者发布方法中的一个引用（如集合引用），这样会导致逸出，带来线程安全问题。且不易维护。 Threadlocal类在每个线程中都有一份变量的备份，实现原理是利用map（ThreadlocalMap， key是threadlocal）。解决了对于每个线程都使用的变量需要同步的问题，比如创建数据库的连接，session管理。 实现应用程序框架时，使用了大量的Threadlocal。如EJB调用，J2EE需要将一个事务上下文与某个执行中的线程关联起来。通过将事物上下文保存在静态的Threadlocal中实现。当框架需要知道当前运行的是哪一个事务的时候，只要从Threadlocal中读取上下文。 这种方法会降低代码的可重用性，带来隐含的耦合。使用时需要小心。 不变性不可变对象一定是线程安全的。 如何构造一个不变的类。 final修饰变量和类 不提供setter方法 构造方法里初始化所有的值 getter方法返回值的clone 对象的clone采用深度复制 类成员变量被修饰成private 安全发布安全地发布一个对象，对象的应用以及对象的状态必须同时对其他线程可见。一个正确构造的对象可以通过以下方式来安全地发布： 在静态初始化函数中初始化一个对象引用 将对象的应用保存到volatile类型的域或者AtomicReferance对象中 将对象的引用保存到某个正确构造对象的final类型域中 将对象的引用保存到一个由锁保护的域中 利用容器线程安全库中的容器类提供了以下的安全发布保证： 通过将一个键或者值放入Hashtable、synchronizedMap或者ConcurrentMap中，可以安全地将它发布给任何从这些容器中访问它的线程（无论是直接访问还是通过迭代器访问） 通过将某个元素放入Vector、CopyOnWriteArrayList、CopyOnWriteArraySet、synchronizedList或synchronizedSet中，可以将该元素安全地发布到任何从这些容器中访问该元素的线程 通过将某个元素放入BlockingQueue或者ConcurrentLinkedQueue中，可以将该元素安全地发布到任何从这些队列中访问该元素的线程。 类库中的其他数据传递机制（例如Future和Exchanger）同样能实现安全发布。 利用静态变量静态初始化器由JVM在类的初始化阶段执行。由于在JVM内部存在着同步机制，因此通过这种方式初始化的任何对象都可以被安全地发布","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java并发","slug":"java并发","permalink":"http://imwyy.github.io/tags/java并发/"}]},{"title":"分布式事务的提交：二阶段提交","slug":"分布式事务的提交：二阶段和三阶段","date":"2018-03-15T07:56:32.000Z","updated":"2018-03-15T08:52:28.802Z","comments":true,"path":"2018/03/15/分布式事务的提交：二阶段和三阶段/","link":"","permalink":"http://imwyy.github.io/2018/03/15/分布式事务的提交：二阶段和三阶段/","excerpt":"","text":"分布式部署的多台机器中的数据保持一致性，那么就要保证在所有节点的数据写操作，要么全部都执行，要么全部的都不执行。但是，一台机器在执行本地事务的时候无法知道其他机器中的本地事务的执行结果。所以他也就不知道本次事务到底应该commit还是 rollback。所以，常规的解决办法就是引入“协调者”来统一调度所有分布式节点的执行。 使用基本事务？？基本事务有三个状态，分别是 激活态：启动事务后即进入激活态 提交态：应用线程提交请求的结果就是激活态转到提交态 中止态：应用线程回退或者因为系统的其他原因（崩溃、死锁等）导致事务从激活态转为中止态。 三者转换图如下： 注意：事务的状态不能逆向转换 显然，基本事务不能满足分布式环境事务提交的要求。 举例说明，假如节点1本地事务T1给账号A余额加上100，节点2远端事务T2给账户A加上100。 一种可能的做法：T1执行完成，提交事务，发一个消息通知远端T2事务提交。但是在这一刻，远端节点2有可能崩溃，则它在恢复时，会中止事务T2。 另一种做法：先发一个消息给T2，让其提交事务。在收到成功提交的消息后，再提交T1。那么节点1可能在收到消息前崩溃，同样会在恢复时，会中止事务T1。 所以继续在事务中添加一个新的状态“准备态“解决这个问题： 添加了准备态之后，事务恢复时，后可以继续提交，而不是直接进入中止态。有了这些，我们来看二阶段提交。 二阶段提交参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 第一阶段：准备 协调者节点向所有参与者节点询问是否可以执行提交操作，并等待各参与者节点的响应。 参与者节点执行所有事务操作，并将Undo信息和Redo信息写入日志。 参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”成功”消息；否则它返回一个”失败”消息。 第二阶段：提交 如果第一阶段所有的参与者都回应“成功”： 协调者节点向所有参与者节点发出”正式提交”的请求。 参与者节点正式完成操作，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”完成”消息。 协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。 如果第一阶段存在参与者回应“失败”： 协调者节点向所有参与者节点发出”回滚操作”的请求。 参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。 参与者节点向协调者节点发送”回滚完成”消息。 协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务 这样可以做到所有事务都要么全部都执行，要么全部的都不执行。但是存在一些问题： 事务阻塞问题： 执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。 死锁问题： 同样因为阻塞问题，会出现两方事务各自拿着对方需要的数据，形成死锁。 单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。 针对这些问题，才会有三阶段提交。之后再研究。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://imwyy.github.io/categories/数据库/"}],"tags":[{"name":"数据库事务","slug":"数据库事务","permalink":"http://imwyy.github.io/tags/数据库事务/"}]},{"title":"leetcode之manacher算法","slug":"leetcode之manacher算法","date":"2018-03-13T04:17:37.000Z","updated":"2018-03-13T05:09:11.033Z","comments":true,"path":"2018/03/13/leetcode之manacher算法/","link":"","permalink":"http://imwyy.github.io/2018/03/13/leetcode之manacher算法/","excerpt":"","text":"Manacher’s algorithm 求最长子回文串用该算法求解最长回文子串，时间和空间复杂度都是O(n)。这里有篇英文解释，可供参考。算法不太好理解，所以在理解的时候记录下来，怕遗忘。 https://articles.leetcode.com/longest-palindromic-substring-part-ii/ 算法思想1. 准备 首先，对回文子串做处理，每个字符之间加入一个无关字符（“#“），如abcd编程#a#b#c#d#，这样做好处是，总能把回文变成奇数个，这样只用考虑由中心向两边拓展的回文。 其次，定义需要用到的数组或变量。 S：处理过后的字符串，可以理解成char数组 P：和s对应长度的数组，数组第i位记录着S第i位为中心，除去#之后的最大的回文的长度（也就是说求出来的长度要去除#的数量）。 所以我们要做的就变成了将P数组中的每个值(除去S对应下表为“#”的位置)都求解出来。 对于P数组，我们可以先将S对应下表为“#”的位置全部置为0（因为我们不需要这些数据，也不需要计算它），同时我们总可以得到P[1] = 1。 而接下来的步骤就是根据已经知道的值来计算后面未知的值。这个计算基于这样显而易见的一个规律： 一个回文串，在中心位置的左半部分边如果是一个子回文串，那么对称的右半部分也会是一个子回文串。 应用在长度上就是， 一个回文串，在中心位置的左半部分边如果是一个子回文串且长度为l，那么对称的右半部分也会是一个子回文串，长度也是l 2. 算法核心 方便理解，再定义一些变量 i：我们目前要求的P[i]的值的下标 center：包含i所在位置的最大的回文子串的中心所在位置的下标 mirror：i关于center的对称点。这个点的P[mirror]已经被求解过 那么按照我们之前所说的规律，P[i] = P[mirror]。 123456 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6T = # b # a # b # c # b # a # b # c # b # a # c # c # b #P = 0 1 0 3 0 1 0 7 0 ? 0 ...i = 9center = 7mirror = 5 但是发现这个结论有问题，并不是都成立。 123456 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6T = # b # a # b # c # b # a # b # c # b # a # c # c # b # P = 0 1 0 3 0 1 0 7 0 1 0 ? ...i = 11center = 7mirror = 3 这里展示了一种不成立的情况：按照之前的假设，P[11] = P[3] = 3，但是事实上P[11] = 9，回文串为`abcbabcba`. 而不成立的时候，都是如下情况： - 以mirror为中心的最大回文字符串 超过了 以center为中心的最大回文字符串 的**控制范围**。 - 换句话说，就是以mirror为中心的最大回文字符串的最左端 超过了 以center为中心的最大回文字符串的最左端。 - 再精确一点，`center-P[center] &gt; mirror - P[mirror]`。注意这里的减的是`P[mirror]` `P[center]`而不是 `P[mirror]/2` `P[center]/2`，因为字符串被填充过`#`，而P记录的长度是不包括`#`的。 基于以上讨论。最终我们只要分为两种情况 若center-P[center] &lt; mirror - P[mirror]，不用计算，P[i] = P[mirror] 若相反，只要按照回文串的判断，一个个比较字符是否相等，得到回文最大的长度。","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://imwyy.github.io/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://imwyy.github.io/tags/leetcode/"}]},{"title":"数据库的锁机制","slug":"数据库的锁机制","date":"2018-03-08T10:11:15.000Z","updated":"2018-03-08T10:11:50.873Z","comments":true,"path":"2018/03/08/数据库的锁机制/","link":"","permalink":"http://imwyy.github.io/2018/03/08/数据库的锁机制/","excerpt":"","text":"前两天刚接到阿里hr的实习电话面试，一直以为对java基础、数据库基础很熟悉，却被问到哑口无言，结果我也不去期盼了，一首凉凉送给自己，可惜啊可惜，总结一句，还是自己太菜。不过也感谢这位java部门的hr，让我意识到真正理解是要能讲出来，要能逻辑一环扣一环，有清晰的知识体系。 下面是面试中问到的数据库的锁机制，今天彻底理清楚。文章中有参考整理其他一些有价值的博客以及mysql官方文档的内容。 数据库锁先看一张图自己整理的数据库锁的树形图 概要数据库锁一般可以分为两类，一个是悲观锁，一个是乐观锁。 乐观锁一般是指用户自己实现的一种锁机制，假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。乐观锁的实现方式一般包括使用版本号和时间戳。 悲观锁一般就是我们通常说的数据库锁机制，以下讨论都是基于悲观锁。 悲观锁主要表锁、行锁、页锁。在MyISAM中只用到表锁，不会有死锁的问题，锁的开销也很小，但是相应的并发能力很差。innodb实现了行级锁和表锁，锁的粒度变小了，并发能力变强，但是相应的锁的开销变大，很有可能出现死锁。同时inodb需要协调这两种锁，算法也变得复杂。InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。 表锁和行锁都分为共享锁和排他锁（独占锁），而更新锁是为了解决行锁升级（共享锁升级为独占锁）的死锁问题。 innodb中表锁和行锁一起用，所以为了提高效率才会有意向锁（意向共享锁和意向排他锁）。 为了表锁和行锁而存在的意向锁官方文档中是这么描述的， Intention locks are table-level locks that indicate which type of lock (shared or exclusive) a transaction requires later for a row in a table 知乎上有个解释十分形象，如下： 在mysql中有表锁，读锁锁表，会阻塞其他事务修改表数据。写锁锁表，会阻塞其他事务读和写。 Innodb引擎又支持行锁，行锁分为共享锁，一个事务对一行的共享只读锁。排它锁，一个事务对一行的排他读写锁。 这两中类型的锁共存的问题考虑这个例子：事务A锁住了表中的一行，让这一行只能读，不能写。之后，事务B申请整个表的写锁。如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了行锁。 数据库要怎么判断这个冲突呢？ step1：判断表是否已被其他事务用表锁锁表 step2：判断表中的每一行是否已被行锁锁住。 注意step2，这样的判断方法效率实在不高，因为需要遍历整个表。于是就有了意向锁。在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。 在意向锁存在的情况下，上面的判断可以改成 step1：不变 step2：发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。 注意：申请意向锁的动作是数据库完成的，就是说，事务A申请一行的行锁的时候，数据库会自动先开始申请表的意向锁，不需要我们程序员使用代码来申请。 行锁的细分 共享锁 加锁与解锁：当一个事务执行select语句时，数据库系统会为这个事务分配一把共享锁，来锁定被查询的数据。在默认情况下，数据被读取后，数据库系统立即解除共享锁。例如，当一个事务执行查询“SELECT * FROM accounts”语句时，数据库系统首先锁定第一行，读取之后，解除对第一行的锁定，然后锁定第二行。这样，在一个事务读操作过程中，允许其他事务同时更新accounts表中未锁定的行。 兼容性：如果数据资源上放置了共享锁，还能再放置共享锁和更新锁。 并发性能：具有良好的并发性能，当数据被放置共享锁后，还可以再放置共享锁或更新锁。所以并发性能很好。 排他锁 加锁与解锁：当一个事务执行insert、update或delete语句时，数据库系统会自动对SQL语句操纵的数据资源使用独占锁。如果该数据资源已经有其他锁（任何锁）存在时，就无法对其再放置独占锁了。 兼容性：独占锁不能和其他锁兼容，如果数据资源上已经加了独占锁，就不能再放置其他的锁了。同样，如果数据资源上已经放置了其他锁，那么也就不能再放置独占锁了。 并发性能：最差。只允许一个事务访问锁定的数据，如果其他事务也需要访问该数据，就必须等待。 更新锁 更新锁在的初始化阶段用来锁定可能要被修改的资源，这可以避免使用共享锁造成的死锁现象。例如，对于以下的update语句： UPDATE accounts SET balance=900 WHERE id=1 更新操作需要分两步：读取accounts表中id为1的记录 –&gt; 执行更新操作。 如果在第一步使用共享锁，再第二步把锁升级为独占锁，就可能出现死锁现象。例如：两个事务都获取了同一数据资源的共享锁，然后都要把锁升级为独占锁，但需要等待另一个事务解除共享锁才能升级为独占锁，这就造成了死锁。 更新锁有如下特征： 加锁与解锁：当一个事务执行update语句时，数据库系统会先为事务分配一把更新锁。当读取数据完毕，执行更新操作时，会把更新锁升级为独占锁。 兼容性：更新锁与共享锁是兼容的，也就是说，一个资源可以同时放置更新锁和共享锁，但是最多放置一把更新锁。这样，当多个事务更新相同的数据时，只有一个事务能获得更新锁，然后再把更新锁升级为独占锁，其他事务必须等到前一个事务结束后，才能获取得更新锁，这就避免了死锁。 并发性能：允许多个事务同时读锁定的资源，但不允许其他事务修改它。 数据库隔离级别了解了数据的锁机制，数据库的隔离级别也就好理解多了。每一种隔离级别满足不同的数据要求，使用不同程度的锁。 Read Uncommitted，读写均不使用锁，数据的一致性最差，也会出现许多逻辑错误。 Read Committed，使用写锁，但是读会出现不一致，不可重复读。 Repeatable Read, 使用读锁和写锁，解决不可重复读的问题，但会有幻读。 Serializable, 使用事务串形化调度，避免出现因为插入数据没法加锁导致的不一致的情况。 读不提交，造成脏读(Read Uncommitted) 一个事务中的读操作可能读到另一个事务中未提交修改的数据，如果事务发生回滚就可能造成错误。 例子：A打100块给B，B看账户，这是两个操作，针对同一个数据库，两个事物，如果B读到了A事务中的100块，认为钱打过来了，但是A的事务最后回滚了，造成损失。 避免这些事情的发生就需要我们在写操作的时候加锁，使读写分离，保证读数据的时候，数据不被修改，写数据的时候，数据不被读取。从而保证写的同时不能被另个事务写和读。 读提交(Read Committed) 我们加了写锁，就可以保证不出现脏读，也就是保证读的都是提交之后的数据，但是会造成不可重读，即读的时候不加锁，一个读的事务过程中，如果读取数据两次，在两次之间有写事务修改了数据，将会导致两次读取的结果不一致，从而导致逻辑错误。 可重读(Repeatable Read） 解决不可重复读问题，一个事务中如果有多次读取操作，读取结果需要一致（指的是固定一条数据的一致，幻读指的是查询出的数量不一致）。 这就牵涉到事务中是否加读锁，并且读操作加锁后是否在事务commit之前持有锁的问题，如果不加读锁，必然出现不可重复读，如果加锁读完立即释放，不持有，那么就可能在其他事务中被修改，若其他事务已经执行完成，此时该事务中再次读取就会出现不可重复读， 所以读锁在事务中持有可以保证不出现不可重复读，写的时候必须加锁且持有，这是必须的了，不然就会出现脏读。Repeatable Read（可重读）也是MySql的默认事务隔离级别，上面的意思是读的时候需要加锁并且保持 可串行化（Serializable） 解决幻读问题，在同一个事务中，同一个查询多次返回的结果不一致。事务A新增了一条记录，事务B在事务A提交前后各执行了一次查询操作，发现后一次比前一次多了一条记录。幻读是由于并发事务增加记录导致的，这个不能像不可重复读通过记录加锁解决，因为对于新增的记录根本无法加锁。需要将事务串行化，才能避免幻读。 这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争 参考文献： https://www.cnblogs.com/luyucheng/p/6297752.htmlhttps://www.zhihu.com/question/51513268https://dev.mysql.com/doc/refman/5.7/en/innodb-locking.html","categories":[{"name":"数据库","slug":"数据库","permalink":"http://imwyy.github.io/categories/数据库/"}],"tags":[{"name":"数据库锁","slug":"数据库锁","permalink":"http://imwyy.github.io/tags/数据库锁/"}]},{"title":"idea项目添加spring","slug":"idea项目添加spring","date":"2018-02-09T03:08:00.000Z","updated":"2018-02-09T05:37:53.322Z","comments":true,"path":"2018/02/09/idea项目添加spring/","link":"","permalink":"http://imwyy.github.io/2018/02/09/idea项目添加spring/","excerpt":"","text":"配置步骤1.添加spring的依赖包idea可以直接右击项目 选择add frame support，勾选spring即可 2.创建applicationContext.xml在src的直接子目录下创建 applicationContext.xml 这里给出一个applicationContext.xml 的实例，以及注释解释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://www.springframework.org/schema/beans\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!-- 扫描有注解的文件 base-package 包路径 --&gt; &lt;context:component-scan base-package=\"service.imp, action, dao.imp\"/&gt; &lt;!-- 定义 Autowired 自动注入 bean --&gt; &lt;bean class=\"org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor\"/&gt; &lt;!-- 声明式容器事务管理 ,transaction-manager指定事务管理器为transactionManager --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.orm.hibernate5.HibernateTransactionManager\"&gt; &lt;property name=\"sessionFactory\" ref=\"sessionFactory\"/&gt; &lt;/bean&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"*User\"/&gt; &lt;tx:method name=\"*\" propagation=\"NOT_SUPPORTED\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 定义切面，在service包及子包中所有方法中,执行有关的hibernate session的事务操作 --&gt; &lt;aop:config&gt; &lt;!-- 只对业务逻辑层实施事务 --&gt; &lt;aop:pointcut id=\"serviceOperation\" expression=\"execution( * service..*.*(..))\"/&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"serviceOperation\"/&gt; &lt;/aop:config&gt; &lt;!-- 配置dataSource --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/j2ee?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;amp;autoReconnect=true\"/&gt; &lt;property name=\"user\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"wyy\"/&gt; &lt;property name=\"initialPoolSize\" value=\"5\"/&gt; &lt;property name=\"maxPoolSize\" value=\"10\"/&gt; &lt;/bean&gt; &lt;!-- 配置sessionFactory --&gt; &lt;bean id=\"sessionFactory\" class=\"org.springframework.orm.hibernate5.LocalSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"packagesToScan\" value=\"model\"/&gt; &lt;property name=\"hibernateProperties\"&gt; &lt;props&gt; &lt;prop key=\"hibernate.dialect\"&gt; org.hibernate.dialect.MySQL57Dialect&lt;/prop&gt; &lt;prop key=\"hibernate.show_sql\"&gt;false&lt;/prop&gt; &lt;prop key=\"hibernate.format_sql\"&gt;true&lt;/prop&gt; &lt;prop key=\"hibernate.hbm2ddl.auto\"&gt;update&lt;/prop&gt; &lt;prop key=\"hibernate.connection.autocommit\"&gt;true&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置hibernateTemplate --&gt; &lt;bean id=\"hibernateTemplate\" class=\"org.springframework.orm.hibernate5.HibernateTemplate\"&gt; &lt;property name=\"sessionFactory\" ref=\"sessionFactory\"/&gt; &lt;/bean&gt;&lt;/beans&gt; 3.给service的实现类添加@Service注解 给dao的实现类添加@Repository注解 将生命周期管理交给spring注意所有交给spring管理的类，不能new出实例，只能用spring注入。 4.所有使用到service和dao的地方，均使用@Autowired注解注入。 @Autowired注解可以在构造函数、类成员属性、getset方法添加注解注入bean，但是类成员属性的注入方法是不推荐的 在stackoverflow上有人做了详细的解释 https://stackoverflow.com/questions/39890849/what-exactly-is-field-injection-and-how-to-avoid-it 总结下来，使用属性注入会产生如下问题 对象和注入的容器有着很紧的耦合 对象间的耦合被隐藏了，外部无法看到，不利于复杂度控制 如果没有注入容器，对象无法创建 当一个类有多个属性注入，你感知不到他的复杂度。而当你使用构造函数注入时，就会发现，要穿入的参数过多。也是不利于复杂度控制 5.dao的实现技术 sessionFactory 123456789101112131415@Repositorypublic class UserDaoImp implements UserDao &#123; private SessionFactory sessionFactory; @Autowired public UserDaoImp(SessionFactory sessionFactory) &#123; this.sessionFactory = sessionFactory; &#125; @Override public User get(String userId) &#123; return sessionFactory.openSession().load(User.class, userId); &#125;&#125; hibernateTemplate 123456789101112131415@Repositorypublic class UserDaoImp implements UserDao &#123; @Autowired private HibernateTemplate hibernateTemplate; public UserDaoImp(HibernateTemplate hibernateTemplate) &#123; this.hibernateTemplate = hibernateTemplate; &#125; @Override public User get(String userId) &#123; return hibernateTemplate.get(User.class, userId); &#125;&#125; hibernateTemplate封装了SessionFactory，数据库操作变得更简单。 如下给出实现hibernateTemplate分页的代码。 123456789101112@Overridepublic List&lt;Order&gt; getListByHql(String hql, int page, int pageSize) &#123; return hibernateTemplate.execute(new HibernateCallback&lt;List&lt;Order&gt;&gt;() &#123; @Override public List&lt;Order&gt; doInHibernate(Session session) throws HibernateException &#123; Query&lt;Order&gt; query = session.createQuery(hql); query.setFirstResult((page - 1) * pageSize).setMaxResults(pageSize); //把结果返回 return query.list(); &#125; &#125;);&#125; 问题与解决nested exception is java.lang.NoClassDefFoundError: org/aspectj/weaver/reflect/ReflectionWorld$ReflectionWorldException这个错误显然是没有找到某个jar包。如果要定义aop，除了spring核心包之外，还需要自行下载这两个jar。 aopalliance.jar aspectjweaver.jar 检查一下jar包，发现没有aspectjweaver.jar，下载并加入到项目路径即可。","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"http://imwyy.github.io/tags/spring/"}]},{"title":"android第三方库导致support版本冲突解决方案","slug":"android引入第三方库导致support版本冲突解决方案","date":"2018-01-26T05:41:24.000Z","updated":"2018-01-26T05:55:58.078Z","comments":true,"path":"2018/01/26/android引入第三方库导致support版本冲突解决方案/","link":"","permalink":"http://imwyy.github.io/2018/01/26/android引入第三方库导致support版本冲突解决方案/","excerpt":"","text":"问题升级compileSdk版本到26，同时修改了support包的版本，报错 all com.android.support libraries must use the exact same version specification(mixing versions can lead to runtime crashes) 也就是说有引入的第三方库和目前编译版本有冲突。 解决一般这种问题解决方案是，在指定的有冲突的库的依赖处，添加 exclude group: &#39;com.android.support&#39;，可以将冲突库不包含在编译，如 123compile(&apos;xx.xxx.xxxxx:xxxxx:1.5.5&apos;) &#123; exclude group: &apos;com.android.support&apos;&#125; 但是问题是我不知道哪个第三方库冲突，不可能一个个检查吧？ 这时候只需要在gradle文件中添加如下代码，让所有的第三方包强制使用指定版本的support包： 12345678910configurations.all &#123; resolutionStrategy.eachDependency &#123; DependencyResolveDetails details -&gt; def requested = details.requested if (requested.group == &apos;com.android.support&apos;) &#123; if (!requested.name.startsWith(&quot;multidex&quot;)) &#123; details.useVersion &apos;26.1.0&apos; &#125; &#125; &#125;&#125; 以及在自己写第三方库给别人用的时候，对于support包的依赖方式改成provided（或者compileOnly，gradle3.0），这样不会把support打包，方便使用的人。 关于gradle3.0更多gradle升级到3.0后，依赖的方式变得更多了，最显著的变化就是，之前一直用的compile可以替换为implementation， 如 1implementation &apos;xx.xxx.xxxxx:xxxxx::1.5.5&apos; implementation是指引入依赖，这个第三方包引入的东西，你在项目里无法使用，有点接口的味道，屏蔽内部实现。可以加快gradle编译的速度。 同样的对于 debugcompile releasecompile 都有debug implementation release implementation 与之对应。","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"}]},{"title":"动态规划之01背包问题及leetcode实例","slug":"动态规划之背包问题及leetcode实例","date":"2018-01-24T05:24:57.000Z","updated":"2018-01-24T07:05:43.201Z","comments":true,"path":"2018/01/24/动态规划之背包问题及leetcode实例/","link":"","permalink":"http://imwyy.github.io/2018/01/24/动态规划之背包问题及leetcode实例/","excerpt":"","text":"01背包问题这篇文章讲的很清楚，我这里就不赘述了。 https://www.cnblogs.com/Christal-R/p/Dynamic_programming.html leetcode problem 416描述Given a non-empty array containing only positive integers,find if the array can be partitioned into two subsets such that the sum of elements in both subsets is equal. 即判断能不能将给定数组分成两份，使他们的和相等。 分析题目就是要从数组中找一个序列，使他们的和为sum/2。如果暴力硬解，挑选的数组子序列个数不定，复杂度太高，肯定不可取。事实上这是一个01背包问题，对于每个数字，要么选中要么不选中。 具体的，用一个二维数组d[i][j]表示，从前i个元素中挑选子序列是否可以计算出和j。那么我们只要知道当j=sum/2的时候，d[i][j]是否为true。 d[i][j]结果的得出，可以有两种情况 d[i-1][j]已经为true，也就是说，已经可以由前i-1个元素中挑选子序列计算出和j，那么d[i][j]自然为true。 d[i-1][j-nums[i]]为true，也就是说，前i-1个元素中挑选子序列计算出和j-nums[i]，那么加上nums[i]刚好可以完成。 python代码1234567891011121314151617181920def canPartition(nums): \"\"\" :type nums: List[int] :rtype: bool \"\"\" half_sum = sum(nums) if half_sum % 2 == 1: return False half_sum = half_sum / 2 d = [[False for x in xrange(half_sum + 1)] for y in xrange(len(nums) + 1)] for k in xrange(len(nums) + 1): d[k][0] = True for i in xrange(1, len(nums) + 1): for j in xrange(0, half_sum + 1): d[i][j] = d[i - 1][j] if j &gt;= nums[i - 1]: d[i][j] = d[i][j] | d[i - 1][j - nums[i - 1]] return d[len(nums)][half_sum]","categories":[{"name":"算法","slug":"算法","permalink":"http://imwyy.github.io/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://imwyy.github.io/tags/算法/"}]},{"title":"gitcommit命令报错","slug":"gitcommit命令报错","date":"2018-01-19T16:00:21.000Z","updated":"2018-01-19T16:03:23.756Z","comments":true,"path":"2018/01/20/gitcommit命令报错/","link":"","permalink":"http://imwyy.github.io/2018/01/20/gitcommit命令报错/","excerpt":"","text":"使用shell写git commit -m命令报错 pathspec &#39;–m&#39; did not match any file(s) known to git.脚本如下 1234cd /Users/Mark.W/Documents/AboutMyself/ git add .git commit -m \"add_upload_picture\"git push origin master 但是在命令行运行没有问题。 最终发现是shell脚本里不用添加“”，去掉引号即可。还是对shell编程不熟悉。 修改后shell为： 1234cd /Users/Mark.W/Documents/AboutMyself/ git add .git commit -m add_upload_picturegit push origin master","categories":[{"name":"shell","slug":"shell","permalink":"http://imwyy.github.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://imwyy.github.io/tags/shell/"}]},{"title":"leetcode note（easy）","slug":"leetcode笔记-easy","date":"2018-01-15T04:37:51.000Z","updated":"2018-01-15T09:37:51.095Z","comments":true,"path":"2018/01/15/leetcode笔记-easy/","link":"","permalink":"http://imwyy.github.io/2018/01/15/leetcode笔记-easy/","excerpt":"","text":"problem 500:Given a List of words, return the words that can be typed using letters of alphabet on only one row’s of American keyboard like the image below. Hashmap regex set and subset problem 496:You are given two arrays (without duplicates) nums1 and nums2 where nums1’s elements are subset of nums2. Find all the next greater numbers for nums1’s elements in the corresponding places of nums2. The Next Greater Number of a number x in nums1 is the first greater number to its right in nums2. If it does not exist, output -1 for this number. hint: map and stack, record the next greater number","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://imwyy.github.io/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://imwyy.github.io/tags/leetcode/"}]},{"title":"idea使用hibernate5","slug":"idea使用hibernate5","date":"2018-01-11T04:12:55.000Z","updated":"2018-01-11T04:13:04.859Z","comments":true,"path":"2018/01/11/idea使用hibernate5/","link":"","permalink":"http://imwyy.github.io/2018/01/11/idea使用hibernate5/","excerpt":"","text":"","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/tags/java/"}]},{"title":"idea使用wildfly创建ejb项目","slug":"idea使用wildfly创建ejb项目","date":"2018-01-05T12:28:34.000Z","updated":"2018-01-14T08:12:27.361Z","comments":true,"path":"2018/01/05/idea使用wildfly创建ejb项目/","link":"","permalink":"http://imwyy.github.io/2018/01/05/idea使用wildfly创建ejb项目/","excerpt":"","text":"准备工作到官网下载wildfy，解压缩即可。 创建EJB端模块 在已有的项目中新建模块（直接新建工程也可以），选择web application和ejb(当时我只选择ejb，发现一直报错找不到war包，部署不上去，勾选了web application就可以部署了，还不知道啥原因) 在src中新建包，我这里是xyz.wyy.order.service,里面新建接口和实现类。（暂时忽略其他包） 接口添加@remote注解，实现类添加@stateless注解 选择edit configrations配置运行，部署到wildfly。在deployment选项卡中，添加生成的war包。 如果要链接数据库，还需要添加mysql-connector.jar的依赖。 创建客户端模块 在已有的项目中新建模块 web application。 从解压缩的wildfly的 bin/client中拷贝出jboss-client.jar文件，复制到项目lib文件里（在src同级目录中新建lib文件夹），并右击jar包，点击add to classpath。 点击file-&gt;Project Structure，在artifacts中，client端的war包新建WEB-INF新建lib文件夹，将ejb的jar包添加进去（刚刚的ejb端已经下载好了，在右侧找ejb，双击就可以），如果jboss-client没有出现在lib里，也将jboss-client添加进去。 新建包xyz.wyy.order.service 将接口拷贝过来，注意这里包的名字必须一样才可以。只需要拷贝接口。 新建xyz.wyy.order.factory包，新建EJBFactory.java 12345678910111213141516public class EJBFactory &#123; private static Object getEJB(String path)&#123; try&#123; Properties jndiProps = new Properties(); jndiProps.put(Context.URL_PKG_PREFIXES,\"org.jboss.ejb.client.naming\"); jndiProps.put(\"jboss.naming.client.ejb.context\", true); final Context context = new InitialContext(jndiProps); return context.lookup(path); &#125;catch (NamingException e)&#123; e.printStackTrace(); &#125; return null; &#125;&#125; 在src目录下新建jboss-ejb-client.properties，并将一下内容拷贝进去。注意替换。 1234567891011endpoint.name=client-endpointremote.connectionprovider.create.options.org.xnio.Options.SSL_ENABLED=falseremote.connections=defaultremote.connection.default.host=localhostremote.connection.default.port=8080remote.connection.default.connect.options.org.xnio.Options.SASL_POLICY_NOANONYMOUS=falseremote.connection.two.host=localhostremote.connection.two.port=8080remote.connection.two.connect.options.org.xnio.Options.SASL_POLICY_NOANONYMOUS=falseremote.connection.default.username=你的wildfly用户名remote.connection.default.password=你的wildfly密码 客户端通过EJBFactory获取接口，强制转换为指定接口，调用方法。比如 123HelloWorld hello = (HelloWorld) EJBFactory.getEJB( \"ejb:/HelloWorldEJB_war_exploded/HelloWorldEJB!edu.nju.session.stateless.HelloWorld\" ); jndi路径解析见下面。 部署运行。 配置数据源（参考这里） 添加Mysql数据库驱动模块到wildfly 在wildfly/modules/system/layer/base/com目录下创建mysql/main目录，将Mysql驱动jar（例如mysql-connector-java-5.1.6.jar）拷贝到此目录下，并同在此目录下创建module.xml文件，添加内容如下： 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;module xmlns=\"urn:jboss:module:1.1\" name=\"com.mysql\"&gt; &lt;resources&gt; &lt;resource-root path=\"mysql-connector-java-5.1.6.jar\"/&gt; &lt;/resources&gt; &lt;dependencies&gt; &lt;module name=\"javax.api\"/&gt; &lt;module name=\"javax.transaction.api\"/&gt; &lt;/dependencies&gt; &lt;/module&gt; 注意这里的rn:jboss:module:1.1具体是什么版本，需要你看看同级目录其他模块用的版本号。 添加驱动配置到wildfly服务器配置文件 编辑wildfly/standalone/configuration/standalone.xml文件，在&lt;subsystem xmlns=”urn:jboss:domain:datasources处datasources，drivers中添加如下内容： 1234567891011121314151617 &lt;driver name=\"mysql\" module=\"com.mysql\"&gt; &lt;xa-datasource-class&gt;com.mysql.jdbc.jdbc2.optional.MysqlXADataSource&lt;/xa-datasource-class&gt; &lt;/driver&gt; ``` 3. 配置数据源 编辑wildfly/standalone/configuration/standalone.xml文件，在&lt;subsystem xmlns=\"urn:jboss:domain:datasources处datasources中添加mysql数据源，如下： ```xml &lt;datasource jndi-name=\"java:/mysqlDS\" pool-name=\"mysqlDSPool\"&gt; &lt;connection-url&gt;jdbc:mysql://localhost:3306/jbossdb&lt;/connection-url&gt; &lt;driver&gt;mysql&lt;/driver&gt; &lt;security&gt; &lt;user-name&gt;admin&lt;/user-name&gt; &lt;password&gt;admin&lt;/password&gt; &lt;/security&gt; &lt;/datasource&gt; 至此，JBoss 7/WildFly中配置使用Mysql数据库完成。 项目中使用的代码如下： 123456try &#123; Context c = new InitialContext(); //初始化数据源 dataSource = (DataSource) c.lookup(\"java:/mysqlDS\");&#125; catch (NamingException e) &#123; e.printStackTrace();&#125; 遇到的问题1. artifact ‘XXXX:war exploded’ has invalid extension一开始新建工程只选择了ejb工程，运行的时候报了这个错。在stackoverflow上的解决方案试了一下，并不能解决问题。索性重新新建了一个module，勾选了ejb和web application，就运行正常了，也不知道什么原因。 2. 找不到ejb对象。一般这种问题都是jndi路径的问题，我的路径为ejb:/version3EJB_war_exploded/HelloWorldEJB!xyz.wyy.order.service.HelloWorld。需要解释一下，ejb:/是ejb固定的命名空间，version3EJB_war_exploded是ejb项目的名字，这个名字是编译部署上wildfly的名字，需要查看out文件夹查看才算准确，默认不一定是就是你取的项目名字，HelloWorldEJB是你注解name的ejb名字，不是bean的类名，xyz.wyy.order.service.HelloWorld是实现类的完整路径。 当然其实在成功部署到wildfly之后，就会看输出信息，直接copy就可以了，也省的你麻烦，比如我的，部署后，有这么一段输出，第一个稍微变一变就是jndi路径了。 3. 错误 Name [ejb:..] is not bound in this Context. Unable to find [ejb:] with root cause javax.naming.NameNotFoundException in Wildfly出现这个错误的时候，首先要检查你的路径是否写正确，参照第二个问题。其次，看看jboss-client.jar是否真的加入到了项目的依赖。 在idea中，简单将jar包复制到你新建的lib目录是不行的，点击file-&gt;Project Structure 这里有的lib才是真正已经添加到项目中，能够使用，否则运行的时候会找不到jar。添加的方法是从右侧Available Element中双击指定的jar包，添加到war输出到war中。（如果右侧没有你的jar包，在你复制过来的jar包上右击，选择add to classpath） 4. 配置wildfly数据源的时候，每次配置完，重新部署wildfly，之前在standalone.xml中添加的配置被重置到初始状态。经历了无数尝试。。发现必须先把wildfly关闭再去配置，否咋配置完再重启，数据都会被重置为上次运行的状态。。 5. 客户端运行的时候，EJB端调用数据库的方法处报错。javax.naming.NameNotFoundException 找不到数据源。！！要检查配置数据源的步骤有没有按着做！！每一步都不能少！！ 我出现这个问题，找了半天bug，最后在wildfly的输出中找到了这个 显然是数据源没有配置好，找不到mysql驱动。去检查一下驱动的配置，f**k，把mysql写成了myql，路径不对。。吐血。 所以配置数据源的时候一定要谨慎，遇到问题，一定不要忘记看完整的log输出","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/tags/java/"}]},{"title":"android图片文件优化","slug":"android图片文件优化","date":"2018-01-04T13:33:05.000Z","updated":"2018-01-04T13:34:42.707Z","comments":true,"path":"2018/01/04/android图片文件优化/","link":"","permalink":"http://imwyy.github.io/2018/01/04/android图片文件优化/","excerpt":"","text":"参考这里一句总结 drawable放在drawable-xxhdpi文件下比较节省内存，避免大图片OOM","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"}]},{"title":"java匿名内部类序列化问题","slug":"java匿名内部类序列化问题","date":"2018-01-04T12:35:28.000Z","updated":"2018-01-04T12:40:00.456Z","comments":true,"path":"2018/01/04/java匿名内部类序列化问题/","link":"","permalink":"http://imwyy.github.io/2018/01/04/java匿名内部类序列化问题/","excerpt":"","text":"遇到一个序列化问题。明明对象已经实现了序列化接口，但是报错无法序列化外部的类（内心os，跟外部类什么关系啊）。最后发现原因是我使用的对象是匿名内部类的子类，继承的父类实现了序列化接口。 匿名内部类的对象会伴随主对象的整个生命周期，并且匿名类必然不会继承序列化接口支持序列化，所以在执行序列化时会发生无法序列化外部类的情况，因为匿名类对象也是一个需要序列化的成员。","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"踩坑","slug":"踩坑","permalink":"http://imwyy.github.io/tags/踩坑/"}]},{"title":"安卓splash页启动优化全解析","slug":"安卓splash页启动优化","date":"2018-01-04T11:47:51.000Z","updated":"2018-01-04T12:31:46.458Z","comments":true,"path":"2018/01/04/安卓splash页启动优化/","link":"","permalink":"http://imwyy.github.io/2018/01/04/安卓splash页启动优化/","excerpt":"","text":"问题一般没有特殊处理，android启动的时候，会出现白屏或者黑屏的状态，体验很差。究其原因，白屏是app在冷启动的时候，初始化，系统自动用默认的背景色来填充屏幕。这个默认的背景色和你定义的app主题有关。比如如果你的主题继承自Theme.AppCompat.Light.NoActionBar，那么启动的时候就是白色。 本章就来解决app启动慢的问题。 解决我所了解到的，一般解决这个问题的方法有两种： 将这个背景色改为透明色。虽然看上去没有白屏的状况，但用户点击app后，原先白屏的那段时间变成了桌面背景，让人感觉启动慢是手机系统的锅，跟app没啥。有点甩锅的意思。 具体做法是在style中添加主题 1234&lt;style name=\"AppTheme.SplashTheme\" parent=\"Theme.AppCompat.Light.NoActionBar\"&gt; &lt;item name=\"android:windowFullscreen\"&gt;true&lt;/item&gt; &lt;item name=\"android:windowIsTranslucent\"&gt;true&lt;/item&gt; &lt;/style&gt; 注意这里`windowIsTranslucent`属性就是设置背景色透明的关键代码。然后在`AndroidManifest`中将启动的那个`activity`的`theme`设置为这个主题 123456789&lt;activity android:name=\".ui.base.SplashActivity_\" android:theme=\"@style/AppTheme.SplashTheme\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"android.intent.action.MAIN\" /&gt; &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt; &lt;/intent-filter&gt;&lt;/activity&gt; 第一种方法说白了只是给用户一个假象，“是你手机系统的问题，不是我app的问题”。既然能把背景改成透明的，那为什么不能直接改成我的splash页的背景图片呢，这样白屏的那段时间，先用这个背景图片，当splash页加载好的时候，无缝衔接，但用户看到的就是，”不错这个很快，点了没有任何停顿，立马启动。“。 具体方法，只要将刚才的那个AppTheme.SplashTheme的属性改一改。 12345&lt;style name=\"AppTheme.SplashTheme\" parent=\"@android:style/Theme.Light.NoTitleBar.Fullscreen\"&gt; &lt;item name=\"android:windowBackground\"&gt;@drawable/splash&lt;/item&gt; &lt;item name=\"android:windowFullscreen\"&gt;true&lt;/item&gt; &lt;item name=\"android:windowIsTranslucent\"&gt;true&lt;/item&gt;&lt;/style&gt; 这里的windowBackground就是设置背景图片的关键代码，那段冷启动的时间，屏幕就被设置成这张图片。接下来使用一样，在AndroidManifest注册使用即可。强力推荐。 再优化搞定了白屏问题，我们再来看看一般app使用splash页启动的方法，可能最一般的做法就是将启动页做成一个Activity，启动完跳转到MainActivity。 SplashActivity -&gt; MainActivity 但是这样是不是有些浪费，SplashActivity运行期间，app应当可以做一些初始化，加载数据的工作，减轻MainActivity的负担。所以SplashActivity就不需要了，splash可以使用全屏的dialog代替，用完直接销毁。如此，app启动更快了。加载完splash， MainActivity 的数据页加载好了。 这里提供一个封装好的实现：SplashDialog 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class SplashScreen &#123; private Dialog splashDialog; private Activity activity; public SplashScreen(Activity activity) &#123; this.activity = activity; &#125; /** * 显示splash图片 * * @param millis 停留时间 毫秒 * */ public void show(final int millis) &#123; Runnable runnable = new Runnable() &#123; public void run() &#123; DisplayMetrics metrics = new DisplayMetrics(); final ImageView root = new ImageView(activity); root.setMinimumHeight(metrics.heightPixels); root.setMinimumWidth(metrics.widthPixels); root.setLayoutParams(new LinearLayout.LayoutParams(ViewGroup.LayoutParams.MATCH_PARENT, ViewGroup.LayoutParams.MATCH_PARENT, 0.0F)); root.setScaleType(ImageView.ScaleType.FIT_XY); //glide加载图片 GlideApp.with(activity) .load(URL_SPLASH_IMAGE) .placeholder(R.drawable.splash) .error(R.drawable.splash) .diskCacheStrategy(DiskCacheStrategy.NONE) .into(root); splashDialog = new Dialog(activity, android.R.style.Theme_NoTitleBar_Fullscreen); Window window = splashDialog.getWindow(); window.setWindowAnimations(R.style.dialog_anim_fade_out); splashDialog.setContentView(root); splashDialog.setCancelable(false); splashDialog.show(); final Handler handler = new Handler(); handler.postDelayed(new Runnable() &#123; public void run() &#123; removeSplash(); &#125; &#125;, millis); &#125; &#125;; activity.runOnUiThread(runnable); &#125; private void removeSplash() &#123; if (splashDialog != null &amp;&amp; splashDialog.isShowing()) &#123; splashDialog.dismiss(); splashDialog = null; &#125; &#125;&#125; 这里我使用了glide来加载图片，你也可以更改为自己的加载工具。 在 MainActivity使用，oncreate之后直接调用，new SplashDialog(this).show(3000);启动页变得只需要一行代码，而且更快，更方便。ps：别忘了给MainActivity 加上之前的主题。 踩坑上面提到了第二种方法，设置背景图片。这里遇到了一个坑，如果有类似问题可以参考。 我的 MainActivity设置了浸入式的状态栏，但是没有设置透明底部导航栏。导致设置背景图片windowBackground的高度是加上了底部导航栏，也就是说导航栏挡住了一部分的背景图片，但是SplashDialog加载的图片是忽略底部导航栏的，这样这两张图就会有个错位，启动的时候，会出现图片的位置移动了一下。 解决方法是，在前面的AppTheme.SplashTheme中，继承自@android:style/Theme.Light.NoTitleBar.Fullscreen，即老版本的theme，不要继承自Theme.AppCompat.Light.NoActionBar。原因猜想是，老版本不支持占用导航栏的空间，自然也就不会有被导航栏挡住的情况。","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"}]},{"title":"servlet response的encodeURL","slug":"servlet-response的encodeURL","date":"2017-12-25T05:59:24.000Z","updated":"2017-12-25T06:20:06.769Z","comments":true,"path":"2017/12/25/servlet-response的encodeURL/","link":"","permalink":"http://imwyy.github.io/2017/12/25/servlet-response的encodeURL/","excerpt":"","text":"问题与解决初学servlet，一直没在意HttpServletResponse的encodeURL方法，所以服务器端返回地址的时候一直这么写的 123 \"&lt;form action=\\\"\" + req.getContextPath() + \"/\\\" method=\\\"post\\\"&gt;\\n\" 直到运行的时候才发现，这里的请求没有发送到服务器端到相应servlet的doPost方法，但是浏览器检查发现，表单的提交地址确实是对的啊。但是每次点击登录，页面不变，只是刷新了以下登录页面。（这里我 登录的get方法是返回静态页面，post方法是表单提交登录）。 最后突然想起来课上提过一句encodeURL方法，改了以下 123 \"&lt;form action=\\\"\" + resp.encodeURL(req.getContextPath()) + \"/\\\" method=\\\"post\\\"&gt;\\n\" 再试一下，一切正常。 网上搜索后，发现。原来encodeURL方法主要作用是跟踪session， Java Servlet API 中提出了跟踪 Session 的另一种机制，如果客户端浏览器不支持 Cookie，Servlet 容器可以重写客户请求的 URL，把 Session ID 添加到 URL 信息中。 HttpServletResponse 接口提供了重写 URL 的方法：public String encodeURL(java.lang.String url)该方法的实现机制为： 先判断当前的 Web 组件是否启用 Session，如果没有启用 Session，直接返回参数 url。 再判断客户端浏览器是否支持 Cookie，如果支持 Cookie，直接返回参数 url；如果不支持 Cookie，就在参数 url 中加入 Session ID 信息，然后返回修改后的 url。 也就是说为了实现即使在客户端不支持cookie的情况下（我们都知道session机制的实现需要一般依靠cookie），也能够在通过在url后拼接sessionid的形式跟踪id。所以在用了encodeURL后，支持跟踪session，我写的登录自然也能成功了。 仍有的疑惑还是上面的例子。我写成这样，仍然可以正常运行： 1\"&lt;form action=\\\"/login/\\\" method=\\\"post\\\"&gt;\\n\" 我将地址硬编码到html中，仍然可以正常运行，这是为什么？默认就是encodeURL后的路径吗？","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java EE","slug":"java-EE","permalink":"http://imwyy.github.io/tags/java-EE/"}]},{"title":"java8新特性总结","slug":"java8新特性总结","date":"2017-12-23T08:51:55.000Z","updated":"2018-01-09T02:07:51.868Z","comments":true,"path":"2017/12/23/java8新特性总结/","link":"","permalink":"http://imwyy.github.io/2017/12/23/java8新特性总结/","excerpt":"","text":"一篇比较详细的文章。戳这里。 概括来说有以下几点： lamada表达式和函数式接口 stream API 流式操作 接口默认实现方法和静态方法 注解的更新 类库的更新，包括 Date API，Base64，支持JavaScript等 关于base64详细戳这里 补充2018-01-09 hashmap底层实现的改变 JDK7之前hashmap又叫散列链表：基于一个数组以及多个链表的实现，hash值冲突的时候，就将对应节点以链表的形式存储。 JDK8中，当同一个hash值（Table上元素）的链表节点数不小于8时，将不再以单链表的形式存储了，会被调整成一颗红黑树。这就是JDK7与JDK8中HashMap实现的最大区别。","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/tags/java/"}]},{"title":"java9新特性","slug":"java9新特性","date":"2017-12-23T04:19:46.000Z","updated":"2017-12-23T09:15:41.458Z","comments":true,"path":"2017/12/23/java9新特性/","link":"","permalink":"http://imwyy.github.io/2017/12/23/java9新特性/","excerpt":"","text":"转载自：https://www.oschina.net/translate/java-9-new-features原文：https://www.pluralsight.com/blog/software-development/java-9-new-features 整理和精简如下： 1. Java 平台级模块系统Java 9 的定义功能是一套全新的模块系统。当代码库越来越大，创建复杂，盘根错节的“意大利面条式代码”的几率呈指数级的增长。这时候就得面对两个基础的问题: 很难真正地对代码进行封装, 而系统并没有对不同部分（也就是 JAR 文件）之间的依赖关系有个明确的概念。每一个公共类都可以被类路径之下任何其它的公共类所访问到, 这样就会导致无意中使用了并不想被公开访问的 API。此外，类路径本身也存在问题: 你怎么知晓所有需要的 JAR 都已经有了, 或者是不是会有重复的项呢? 模块系统把这俩个问题都给解决了。 模块化的 JAR 文件都包含一个额外的模块描述器。在这个模块描述器中, 对其它模块的依赖是通过 “requires” 来表示的。另外, “exports” 语句控制着哪些包是可以被其它模块访问到的。所有不被导出的包默认都封装在模块的里面。如下是一个模块描述器的示例，存在于 “module-info.java” 文件中: 12345module blog &#123; exports com.pluralsight.blog; requires cms;&#125; 2. JShell: 交互式 Java REPL许多语言已经具有交互式编程环境，Java 现在加入了这个俱乐部。您可以从控制台启动 jshell ，并直接启动输入和执行 Java 代码。 jshell 的即时反馈使它成为探索 API 和尝试语言特性的好工具。 一个例子： 测试某个功能或使用的时候，不用再打开编辑器，然后写public static void main(String[] args)，方便很多。 3. 集合工厂方法通常，您希望在代码中创建一个集合（例如，List 或 Set ），并直接用一些元素填充它。 实例化集合，几个 “add” 调用，使得代码重复。 Java 9，添加了几种集合工厂方法：List.of, Set.of。这样构造集合就方便了很多。如： 4.私有接口方法Java 8 为我们带来了接口的默认方法。 接口现在也可以包含行为，而不仅仅是方法签名。 但是，如果在接口上有几个默认方法，代码几乎相同，会发生什么情况？ 通常，您将重构这些方法，调用一个可复用的私有方法。 但默认方法不能是私有的。 将复用代码创建为一个默认方法不是一个解决方案，因为该辅助方法会成为公共API的一部分。 使用 Java 9，您可以向接口添加私有辅助方法来解决此问题： 1234567891011public interface MyInterface &#123; void normalInterfaceMethod(); default void interfaceMethodWithDefault() &#123; init(); &#125; default void anotherDefaultMethod() &#123; init(); &#125; // This method is not part of the public API exposed by MyInterface private void init() &#123; System.out.println(\"Initializing\"); &#125;&#125; 5. HTTP/2Java 9 中有新的方式来处理 HTTP 调用。这个迟到的特性用于代替老旧的 HttpURLConnection API，并提供对 WebSocket 和 HTTP/2 的支持。注意：新的 HttpClient API 在 Java 9 中以所谓的孵化器模块交付。也就是说，这套 API 不能保证 100% 完成。不过你可以在 Java 9 中开始使用这套 API： 123456789HjttpClient client = HttpClient.newHttpClient();HttpRequest req = HttpRequest.newBuilder(URI.create(\"http://www.google.com\")) .header(\"User-Agent\",\"Java\") .GET() .build(); HttpResponse&lt;String&gt; resp = client.send(req, HttpResponse.BodyHandler.asString()); 除了这个简单的请求/响应模型之外，HttpClient 还提供了新的 API 来处理 HTTP/2 的特性，比如流和服务端推送。","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/tags/java/"}]},{"title":"leetcode之wordsearch","slug":"leetcode之wordsearch","date":"2017-12-23T03:20:08.000Z","updated":"2017-12-23T03:30:29.954Z","comments":true,"path":"2017/12/23/leetcode之wordsearch/","link":"","permalink":"http://imwyy.github.io/2017/12/23/leetcode之wordsearch/","excerpt":"","text":"ProblemGiven a 2D board and a word, find if the word exists in the grid. The word can be constructed from letters of sequentially adjacent cell, where “adjacent” cells are those horizontally or vertically neighboring. The same letter cell may not be used more than once. For example,Given board = 12345[ [&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;E&apos;], [&apos;S&apos;,&apos;F&apos;,&apos;C&apos;,&apos;S&apos;], [&apos;A&apos;,&apos;D&apos;,&apos;E&apos;,&apos;E&apos;]] word = “ABCCED”, -&gt; returns true, word = “SEE”, -&gt; returns true, word = “ABCB”, -&gt; returns false. 思考自己考虑采用map记录每个位置的字母，遍历给定的单词字符，比较每个位置是否是相邻。但是不同位置可以出现相同字母，就比较棘手。 又想构建树，一个单词就是一条树中的一条路径。但是跟节点无法确定，如果遍历board每个节点都构造树，未免太麻烦。 Solution1234567891011121314151617181920212223boolean exist(char[][] board, String word) &#123; char[] w = word.toCharArray(); for (int y = 0; y &lt; board.length; y++) &#123; for (int x = 0; x &lt; board[y].length; x++) &#123; if (exist(board, y, x, w, 0)) return true; &#125; &#125; return false; &#125; private boolean exist(char[][] board, int y, int x, char[] word, int i) &#123; if (i == word.length) return true; if (y &lt; 0 || x &lt; 0 || y == board.length || x == board[y].length) return false; if (board[y][x] != word[i]) return false; board[y][x] ^= 256; boolean exist = exist(board, y, x + 1, word, i + 1) || exist(board, y, x - 1, word, i + 1) || exist(board, y + 1, x, word, i + 1) || exist(board, y - 1, x, word, i + 1); board[y][x] ^= 256; return exist; &#125; 查看了leetcode大神的解答。用了递归。 这里比较巧妙的是board[y][x] ^= 256;，利用异或操作为为每个位置的char记录是否被访问。字母的ascii码小于128，这里异或256即10000000，异或0即是本身，所以低位没变，但是高位改变，没有字母能和异或后的结果相等，也就达到了记录是否被访问的效果，节省空间还方便。","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://imwyy.github.io/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://imwyy.github.io/tags/leetcode/"}]},{"title":"servlet单例多线程","slug":"servlet单例多线程机制","date":"2017-12-22T11:30:44.000Z","updated":"2017-12-22T12:00:59.555Z","comments":true,"path":"2017/12/22/servlet单例多线程机制/","link":"","permalink":"http://imwyy.github.io/2017/12/22/servlet单例多线程机制/","excerpt":"","text":"转载自：https://www.cnblogs.com/yjhrem/articles/3160864.html 将原文进行了修整和精简 Servlet如何处理多个请求访问？Servlet容器默认是采用单实例多线程的方式处理多个请求的： 当web服务器启动的时候（或客户端发送请求到服务器时），Servlet就被加载并实例化(只存在一个Servlet实例) 容器初始化化Servlet主要就是读取配置文件（例如tomcat,可以通过servlet.xml的设置线程池中线程数目，初始化线程池通过web.xml,初始化每个参数值等等。 当请求到达时，Servlet容器通过调度线程(Dispatchaer Thread) 调度它管理下线程池中等待执行的线程（Worker Thread）给请求者 线程执行Servlet的service方法 请求结束，放回线程池，等待被调用（注意：避免使用实例变量（成员变量），因为如果存在成员变量，可能发生多线程同时访问该资源时，都来操作它，照成数据的不一致，因此产生线程安全问题） 从上面可以看出： 第一：Servlet单实例，减少了产生servlet的开销； 第二：通过线程池来响应多个请求，提高了请求的响应时间； 第三：Servlet容器并不关心到达的Servlet请求访问的是否是同一个Servlet还是另一个Servlet，直接分配给它一个新的线程；如果是同一个Servlet的多个请求，那么Servlet的service方法将在多线程中并发的执行； 第四：每一个请求由ServletRequest对象来接受请求，由ServletResponse对象来响应该请求； 如何开发线程安全的Servlet 实现 SingleThreadModel 接口 该接口指定了系统如何处理对同一个Servlet的调用。如果一个Servlet被这个接口指定,那么在这个Servlet中的service方法将不会有两个线程被同时执行，当然也就不存在线程安全的问题。 如果一个Servlet实现了SingleThreadModel接口，Servlet引擎将为每个新的请求创建一个单独的Servlet实例，这将引起大量的系统开销。SingleThreadModel在Servlet2.4中已不再提倡使用 同步对共享数据的操作 使用synchronized 关键字能保证一次只有一个线程可以访问被保护的区段，在本论文中的Servlet可以通过同步块操作来保证线程的安全 避免使用实例变量 本实例中的线程安全问题是由实例变量造成的，只要在Servlet里面的任何方法里面都不使用实例变量，那么该Servlet就是线程安全的。","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java EE","slug":"java-EE","permalink":"http://imwyy.github.io/tags/java-EE/"}]},{"title":"servlet的filter使用替换流","slug":"servlet的filter使用替换流","date":"2017-12-22T04:59:22.000Z","updated":"2017-12-22T11:31:34.240Z","comments":true,"path":"2017/12/22/servlet的filter使用替换流/","link":"","permalink":"http://imwyy.github.io/2017/12/22/servlet的filter使用替换流/","excerpt":"","text":"servlet过滤器工作流程 servlet过滤器在request到达servlet前可以拦截，在response到达客户端之前可以捕获。这样便可以在过滤器中处理一些请求响应的前置操作或通用操作。 常见的一种应用就是进行敏感词过滤。 但是如果直接使用HttpServletResponse，这是一个流，无法对已经out.println()的内容进行修改。所以这里需要替代流。 替代流（stand-in stream）原理在请求到达servlet之前拦截HttpServletResponse，将HttpServletResponse封装成替代流，之后servlet操作的对象即是这个封装后的替代流。这里的封装本质上就是建立一个输出缓冲区，servlet的所有输出都输出到了这个缓冲区，并没有直接写入真正的HttpServletResponse。 然后在响应返回阶段，捕获之前封装的HttpServletResponse，然后将servlet中输出到缓冲区的内容，进行敏感词过滤。 实现利用HttpServletResponseWrapper包装HttpServletResponse，并重写输出流的方法。 一种实现方法如下： 12345678910111213141516171819public class BufferedResponse extends HttpServletResponseWrapper &#123; private PrintWriter printWriter; private CharArrayWriter charArrayWriter; public BufferedResponse(HttpServletResponse response) &#123; super(response); charArrayWriter = new CharArrayWriter(); printWriter = new PrintWriter(bufferedWriter); &#125; @Override public PrintWriter getWriter() &#123; return printWriter; &#125; public String getOutput() &#123; return charArrayWriter.toString(); &#125; &#125; 过滤器中使用： 1234567891011@Overridepublic void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; BufferedResponse bufferedResponse = new BufferedResponse(servletResponse); // filterChain.doFilter 这里指继续处理后续步骤 filterChain.doFilter(servletRequest, bufferedResponse); //这里servlet已经处理完，output即servlet的输出，在这里替换敏感词 String output = bufferedResponse.getOutput(); &#125; 以及如果对CharArrayWriter陌生，点击这里 CharArrayWriter","categories":[{"name":"java","slug":"java","permalink":"http://imwyy.github.io/categories/java/"}],"tags":[{"name":"java EE","slug":"java-EE","permalink":"http://imwyy.github.io/tags/java-EE/"}]},{"title":"android.content.res.Resources$NotFoundException","slug":"android.content.res.Resources$NotFoundException","date":"2017-12-21T12:57:48.000Z","updated":"2017-12-21T13:02:56.281Z","comments":true,"path":"2017/12/21/android.content.res.Resources$NotFoundException/","link":"","permalink":"http://imwyy.github.io/2017/12/21/android.content.res.Resources$NotFoundException/","excerpt":"","text":"Android报“android.content.res.Resources$NotFoundException: String resource ID xxx”错误错误情形使用TextView的setText方法，报错资源找不到。 1.setText(R.id.read_num,item.getReadNum()) 解决这里item.getReadNum()是一个int，setText方法如果直接穿一个数字参数，会被当作是资源id，定位该资源发现找不到就会爆粗。所以只要转成字符串就可以了。1.setText(R.id.read_num, “” + item.getReadNum())","categories":[{"name":"踩坑","slug":"踩坑","permalink":"http://imwyy.github.io/categories/踩坑/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"},{"name":"踩坑","slug":"踩坑","permalink":"http://imwyy.github.io/tags/踩坑/"}]},{"title":"自定义圆角的textview","slug":"自定义圆角的textview","date":"2017-12-19T13:44:27.000Z","updated":"2017-12-19T15:29:56.538Z","comments":true,"path":"2017/12/19/自定义圆角的textview/","link":"","permalink":"http://imwyy.github.io/2017/12/19/自定义圆角的textview/","excerpt":"","text":"给textview添加圆角如果想给一个普通的textview添加圆角、边框等，一般的做法是写一个drawable文件，通过android:background=&quot;@drawable/xxxx&quot;设置为textview的背景。麻烦是不麻烦，可是如果项目里出现了很多需要圆角或者边框的需求时，drawable文件会变得很多很乱，维护起来也十分不方便。 如果直接可以通过属性设置radius border borderWidth等属性值，就会方便很多。github上有一个 SuperTextView ，可以实现。但是功能太多太杂了。搜了搜网上的写法，基本都是重新定义view，重写onDraw onMeasure ，可是这些功能textview都有，没必要，况且重写之后，textview的很多功能就没了。 这里的思路是，通过继承TextView来自定义Textview，利用代码来控制drawable文件。代码创建drawable文件的方式如下： 自定义view的方式有三种：组合、继承、完全自定义 123GradientDrawable gd = new GradientDrawable();//创建drawablegd.setColor(rtvBgColor);gd.setCornerRadius(rtvRadius); 所以方法就是，自定义属性，通过属性值创建drawable文件控制圆角、边框等。如果不设置自定义属性，和一个普通TextView没有任何差别！ 代码12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 支持圆角的TextView * Created by stephen on 2017/12/18. */public class RoundTextView extends android.support.v7.widget.AppCompatTextView &#123; public RoundTextView(Context context) &#123; this(context, null); &#125; public RoundTextView(Context context, @Nullable AttributeSet attrs) &#123; this(context, attrs, 0); &#125; public RoundTextView(Context context, @Nullable AttributeSet attrs, int defStyleAttr) &#123; super(context, attrs, defStyleAttr); TypedArray attributes = context.getTheme().obtainStyledAttributes(attrs, R.styleable.RoundTextView, defStyleAttr, 0); if (attributes != null) &#123; int rtvBorderWidth = attributes.getDimensionPixelSize(R.styleable.RoundTextView_rtvBorderWidth, 0); int rtvBorderColor = attributes.getColor(R.styleable.RoundTextView_rtvBorderColor, Color.BLACK); float rtvRadius = attributes.getDimension(R.styleable.RoundTextView_rtvRadius, 0); int rtvBgColor = attributes.getColor(R.styleable.RoundTextView_rtvBgColor, Color.WHITE); attributes.recycle(); GradientDrawable gd = new GradientDrawable();//创建drawable gd.setColor(rtvBgColor); gd.setCornerRadius(rtvRadius); if (rtvBorderWidth &gt; 0) &#123; gd.setStroke(rtvBorderWidth, rtvBorderColor); &#125; this.setBackground(gd); &#125; &#125; public void setBackgroungColor(@ColorInt int color) &#123; GradientDrawable myGrad = (GradientDrawable) getBackground(); myGrad.setColor(color); &#125;&#125; 在attr中添加属性 1234567&lt;!--支持圆角的TextView--&gt;&lt;declare-styleable name=\"RoundTextView\"&gt; &lt;attr name=\"rtvBgColor\" format=\"color\"/&gt; &lt;attr name=\"rtvBorderWidth\" format=\"dimension\"/&gt; &lt;attr name=\"rtvBorderColor\" format=\"dimension\"/&gt; &lt;attr name=\"rtvRadius\" format=\"dimension\"/&gt;&lt;/declare-styleable&gt; 代码使用 12345678&lt;io.github.imwyy.RoundTextView android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:text=\"浏览\" android:textColor=\"@color/text_black_select_color\" android:textSize=\"@dimen/sp_14\" app:rtvRadius=\"6dp\" app:rtvBgColor=\"@color/colorSearchArea\"/&gt; 这样显然就方便很多了。","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"},{"name":"踩坑","slug":"踩坑","permalink":"http://imwyy.github.io/tags/踩坑/"}]},{"title":"数据结构之树","slug":"数据结构之树","date":"2017-12-19T03:39:13.000Z","updated":"2017-12-19T15:33:52.053Z","comments":true,"path":"2017/12/19/数据结构之树/","link":"","permalink":"http://imwyy.github.io/2017/12/19/数据结构之树/","excerpt":"","text":"二叉树 每个结点最多有两颗子树，结点的度最大为2 左子树和右子树是有顺序的，次序不能颠倒 节点数为n的树 深度至多为n 至少为log2(n+1)向下取整 对于任何一棵非空的二叉树,如果叶节点个数为n0，度数为2的节点个数为n2，则有: n0 = n2 + 1 存储二叉树结构的方法一般有三种，数组、链表、游标 满二叉树高度为h的满二叉树拥有刚刚好(2^h+1 )-1个节点 完全二叉树若二叉树高度为h，除h层外其他所有层节点个数都达到了最大个数。若h层有叶节点，则所有的叶节点从左到右排列。这就是完全二叉树 具有n的结点的完全二叉树的深度为log2n+1. 如果有一颗有n个节点的完全二叉树的节点按层次序编号，对任一层的节点i（1&lt;=i&lt;=n）有 如果i=1，则节点是二叉树的根，无双亲，如果i&gt;1，则其双亲节点为[i/2]，向下取整 如果2i&gt;n那么节点i没有左孩子，否则其左孩子为2i 如果2i+1&gt;n那么节点没有右孩子，否则右孩子为2i+1 tips: 编号后，左子节点的编号是父节点编号的两倍 参考 二叉树的遍历 前序遍历:根—左—右。 递归实现 非递归实现 思路：每次访问树的左节点，并将节点入栈。如果左节点为空，就取栈顶出栈，访问栈顶节点的右节点，并继续访问入栈访问左节点。代码如下： 12345678910111213141516void preOrderTraverse(Tree t) &#123; Stack s; Tree tmp = t; while((tmp != NULL) || !isEmpty(&amp;s)) &#123; while(tmp != NULL) &#123; Push(&amp;s, tmp); visit(&amp;tmp); tmp = tmp-&gt;lchild; &#125; if(!isEmpty(&amp;s)) &#123; Pop(&amp;s, &amp;tmp); tmp = tmp-&gt;rchild; &#125; &#125;&#125; 中序遍历: 左-根-右 递归实现 非递归实现 若其左孩子不为空，则将t入栈，并将t的左孩子设置为当前的t 若其左孩子为空，则取栈顶元素并进行出栈操作，访问该结点。然后将当前的t置为栈顶结点的右孩子 直到t为空并且栈为空，则遍历结束。 1234567891011121314151617void inOrderTraverse(Tree t) &#123; Stack s; Tree tmp = t; while((tmp != NULL) || !isEmpty(&amp;s)) &#123; while(tmp != NULL) &#123; Push(&amp;s, tmp); tmp = tmp-&gt;lchild; &#125; if(!isEmpty(&amp;s)) &#123; Pop(&amp;s, &amp;tmp); visit(&amp;tmp); tmp = tmp-&gt;rchild; &#125; &#125;&#125; 后序遍历: 左-右-根 递归实现 非递归实现 确保在访问父节点之前左右子节点都已经被访问。当前节点如果没有子节点，或者当前节点的子节点都被访问的时候，可以访问当前节点。否则将当前节点的子节点入栈。 12345678910111213141516171819202122232425void postOrderTraverse(Tree t) &#123; Stack s; Tree cur = NULL; Tree pre = NULL; Push(&amp;s, t); while(!isEmpty(&amp;s) &#123; Top(&amp;s, &amp;cur); if((cur-&gt;lchild == NULL &amp;&amp; cur-&gt;rchild == NULL)) || (cur-&gt;lchild == NULL &amp;&amp; pre != NULL &amp;&amp; pre == cur-&gt;rchild) || (cur-&gt;rchild == NULL &amp;&amp; pre != NULL &amp;&amp; pre == cur-&gt;lchild)) &#123; Pop(&amp;s, &amp;cur); visit(cur); pre = cur; &#125; else &#123; if(cur-&gt;lchild) &#123; Push(&amp;s, cur-&gt;lchild); &#125; if(cur-&gt;rchild) &#123; Push(&amp;s, cur-&gt;rchild); &#125; &#125; &#125; &#125;&#125; 二叉树的创建 使用访问序列建立二叉树，如 先序:ABDCEGFHI 中序:DBAEGCHFI tips: 如果仅仅知道二叉树的先序遍历和后序遍历，无法确定二叉树 使用广义表来构造，如：A(B(D), C(E( ,G), F(H,I))) 线索树n个结点的二叉树有2n个链域，其中真正有用的是n – 1个，其它n + 1个都是空域。 为了充分利用结点中的空域，使得对某些运算更快，如前驱或后继等运算。 二叉树的应用：霍夫曼编码参考链接","categories":[{"name":"干货","slug":"干货","permalink":"http://imwyy.github.io/categories/干货/"}],"tags":[{"name":"干货","slug":"干货","permalink":"http://imwyy.github.io/tags/干货/"}]},{"title":"glide缓存无法更新","slug":"glide缓存无法更新","date":"2017-12-15T01:47:10.000Z","updated":"2017-12-15T02:10:06.438Z","comments":true,"path":"2017/12/15/glide缓存无法更新/","link":"","permalink":"http://imwyy.github.io/2017/12/15/glide缓存无法更新/","excerpt":"","text":"问题使用glide加载图片，glide有缓存，分为内存缓存和磁盘缓存，可以通过diskCacheStrategy设置不同的缓存策略。具体可以看官方文档（我使用的是glideV4 国内的介绍还比较少）。但是对于指定的url的图片，会出现服务器端的图片已经改变，但是本地加载的时候，glide发现有缓存，不会重新从服务器加载，导致一直显示老的图片。 解决 如果将diskCacheStrategy设置为NONE，内存缓存依然存在。可以设置 skipMemoryCache(true)，这样每次加载都会从服务器重新加载。但是这样耗费流量，加重服务器负担。不好。 翻阅官方文档发现glide有个signature，就是为了解决这个问题。因为glide缓存是采&lt;K, V&gt;键值对存储，如果加载一个url的图片，K就是url，url不变，那么缓存V也不会变。signature的作用就是可以在K上附加一写Key，也就是我们可以在加载图片的时候，存储一个表明当前版本的时间戳，当更新时，改变时间戳，时间戳改变也就是K改变，那么就会重新加载图片。 具体实现如下： 加载图片，根据sp时间戳添加signature： 1234567GlideApp.with(view.getContext()) .load(AppConstants.URL_USER_HEAD + uid) .signature(new ObjectKey(SPUtils.getInstance(AppConstants.SP_NAME_USER).getString(\"head_signature\", \"\"))) .diskCacheStrategy(DiskCacheStrategy.AUTOMATIC) .placeholder(R.drawable.user_default_head) .error(R.drawable.user_default_head) .into(view); 更新图片时，同时更新sp的时间戳： 12SPUtils.getInstance(AppConstants.SP_NAME_USER) .put(\"head_signature\",String.valueOf(System.currentTimeMillis())); 这里有个不知道是不是问题的问题，每次加载都要读取sp，可能会有影响。 注意官方文档有一句话 Urls - Although the best way to invalidate urls is to make sure the server changes the url and updates the client when the content at the url changes, you can also use ObjectKey to mix in arbitrary metadata (such as a version number) instead. 也就是说最好的方式就是让服务器加一个时间戳，可是这样实现起来可能就不是很简单。暂时没有尝试。尝试了再来补充。先记下了。","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"踩坑","slug":"踩坑","permalink":"http://imwyy.github.io/tags/踩坑/"}]},{"title":"android干货集","slug":"android干货集","date":"2017-12-13T01:32:49.000Z","updated":"2017-12-19T15:30:34.301Z","comments":true,"path":"2017/12/13/android干货集/","link":"","permalink":"http://imwyy.github.io/2017/12/13/android干货集/","excerpt":"","text":"glide使用glide和Picasso的区别ConstraintLayout解析","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"},{"name":"干货","slug":"干货","permalink":"http://imwyy.github.io/tags/干货/"}]},{"title":"alfred的workflow登录校园网，自制github图床","slug":"alfred的workflow","date":"2017-12-12T07:58:41.000Z","updated":"2018-01-20T04:24:33.798Z","comments":true,"path":"2017/12/12/alfred的workflow/","link":"","permalink":"http://imwyy.github.io/2017/12/12/alfred的workflow/","excerpt":"","text":"关于alfred之前也一直使用被称为mac神器到alfred。直到今天才发现我用的是低版本，功能非常基础。而高版本所支持的workflow才是真的称为神器。alfred下载猛戳这里这里。至于powerpack的一些功能，可以选择购买使用或者…（滑稽脸） workflowworkflow就是让alfred直接执行脚本，包括shell、python、php等，直接那两个例子来解释，就知道他有多方便了。更多操作查看我的github仓库 登录校园网（使用python脚本）在之前用旧版本的alfred登录校园网所用的方法是在feature添加web url，输入p打开p.nju.edu.cn。然后点击输入浏览器记住的密码登陆。相比打开浏览器页面已经快捷很多。但是如果使用workflow直接快捷键‘opt+p’可以登录校园网，登录成功后有提示音和notification；‘opt+o’可以退出登录校园网，退出成功后有提示音和notification； 步骤如下： preference中点击workflow,按照如图选择keyword to script 输入关键字和描述，保存 右键创建script 输入执行的脚本并保存 123456789101112131415161718192021222324# -*- coding:utf-8 -*-import jsonimport urllibimport urllib2def login(): url = 'http://p.nju.edu.cn/portal_io/login' username = 'xxxx' # 可将密码等保存至文件 password = 'xxxxx' data = &#123;'username': username, 'password': password&#125; postdata = urllib.urlencode(data).encode('utf-8') try: request = urllib2.Request(url, postdata) response = urllib2.urlopen(request) res = json.loads(response.read().decode('utf-8')) # print res[\"reply_code\"] except Exception as e: print(e) if __name__ == '__main__': login() 快捷键打开alfred输入框，输入你的关键字，回车。就连上了校园网，很方便。 workflow让github变成最快捷的图床写markdown的都知道，图片需要url，如果需要本地一张图片显示要先上传，获取url，这就显得麻烦。能不能有个软件，选中图片，按个快捷键，就可以上传图片拿到图片的url呢？ workflow可以做到。 （本来打算学一学写个mac应用的，没想到workflow一个shell脚本就可以了） 步骤如下： 新建如下工作流。可根据自己需要更改。需要注意的是hotkey里argument选择selection in macOS,快捷键可以自己定义 编写shell脚本 12345678#!/bin/basht=$(date +%s)cp '&#123;query&#125;' /Users/Mark.W/Documents/AboutMyself/picBed/Screenshot$&#123;t&#125;.pngcd /Users/Mark.W/Documents/AboutMyself/ git add . &gt; /dev/nullgit commit -m add_upload_picture_$&#123;t&#125; &gt; /dev/nullgit push origin master &gt; /dev/nullecho http://raw.githubusercontent.com/IMWYY/AboutMyself/master/picBed/Screenshot$&#123;t&#125;.png 这里{query}是选中文件的路径，先将其拷贝至git本地仓库，然后再用git命令提交即可。这里有几个注意点： {query}要加上引号，以防遇到文件名里有空格，cp命令会将其拆分当成命令参数。 git命令都有命令回显，而我需要到clipboard的内容只需要是图片url，为了防止干扰，命令后加上&gt; /dev/null回显信息定位到“黑洞”。 git上图片链接地址需要加上raw。我这里用的仓库是AboutMyself。 使用git命令需要配置好git本地的一些参数，ssh key，账号密码之类 这样既可以方便写markdown，还能让你的github经常提交变得绿油油。。岂不美滋滋 部署hexo博客（使用shell脚本）一般部署hexo博客要输入三条命令hexo clean hexo g hexo d。每次都要打开终端输入三个命令真的很麻烦，进阶方法是将命令写成shell脚本，打开终端执行./xxx.sh。当然也可以利用alfred，连终端都不用自己打开。 1 2 3步骤和上个例子一样，不过第四步选择terminal command 然后输入脚本 1cd 你的博客本地目录 &amp;&amp; hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 写完博客，快捷键打开alfred输入框，输入你定义的关键字，回车。部署完成。同理也可以将博客创建的几条命令放在shell脚本用workflow打开。 问题照理说命令应该选择script，但是不奏效，debug（workflow页面有个小虫子，就是debug）发现找不到hexo命令，我明明安装的是全局hexo命令。所以选择terminal command。找到原因了再来改。","categories":[{"name":"小玩意","slug":"小玩意","permalink":"http://imwyy.github.io/categories/小玩意/"}],"tags":[{"name":"小玩意","slug":"小玩意","permalink":"http://imwyy.github.io/tags/小玩意/"}]},{"title":"数据库索引","slug":"数据库索引","date":"2017-12-12T03:03:39.000Z","updated":"2017-12-19T15:30:17.348Z","comments":true,"path":"2017/12/12/数据库索引/","link":"","permalink":"http://imwyy.github.io/2017/12/12/数据库索引/","excerpt":"","text":"1.范式与反范式1.1 范式 第一范式 符合1NF的关系中的每个属性都不可再分，是所有关系型数据库的最基本要求 第二范式 数据表里的所有非主属性都要和该数据表的主键有完全依赖关系；如果有哪些非主属性只和主键的一部份有关的话，它就不符合第二范式；如果一个数据表的主键只有单一一个字段的话，它就一定符合第二范式 第三范式 指数据库中不能存在传递函数依赖关系；关系（表）中的非主属性（非关键字段）不存在对候选键的传递依赖的性质，也指每个非主属性都独立于其他非主属性，并依赖于候选键。 1.2 反范式 范式的满足便于数据一致性的控制，数据冗余会导致数据一致性的控制变得复杂。规范化的数据都是低效的。引入可以控制的冗余可以提高数据库性能 所有的冗余都是为了减少表连接的数量，使用触发器可以解决冗余导致的数据不一致（但是触发器可能会导致循环更改） 数据库反范式设计的七种情形 合并一对一关系 如果双方都是完全参与，那么某个表直接可以作为另一张表的属性直接合并。若有一方是部分参与，把完全参与的并入部分参与的会出现空值，将部分参与并入完全参与的可以。若双方都是部分参与，一定会出现空值，这样就很难确定主键。 拷贝一对多关系中的非主键值 一部电影可能有多个录像带出租某个录像带的日租金时，需要查询video表获得该电影的租金。解决方案是在录像带表添加一个租金字段，并设置触发器 拷贝一对多关系中的外键 拷贝多对多关系中的属性 演员演某一步电影，role表只记录了catelogNo和actorNo，如果要查电影名字就比较困难。role表添加一个电影名称属性。 引入重复组 常见做法：在customer表中引入一条addr字段，放最常用地址，address表中存储所有地址 创建提取表 适用查询实时性不高的情况。。extract table的表中内容和原表可能都相同，只是组织结构不同，有可能一个是为了车查询而建的表（将经常被查询的数据提前计算出来存入该表，会有大量冗余，但是提高效率），另一个是为了update的，一定程度上实现了读写分离。 分区表 将表分成小部分的分区。水平分区：将记录分在不同的表中；竖直分区：将属性分在不同的表中，主键重复。分区对于存储和分析大量数据的应用有好处。 2.索引###2.1 索引概念 索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。是一种以原子粒度访问数据的手段，而不是为了大量数据的访问。是一种数据访问方式；索引是顺序存取。 索引分类 聚簇索引：按照数据存放的物理位置为顺序的，索引的叶节点就是物理上的叶节点，聚簇索引能提高多行检索的速度 非聚簇索引；索引顺序与数据物理排列顺序无关，叶节点仍然是索引节点，保留一个指针指向数据块，非聚簇索引对于单行的检索很快。 一个表最多只能有一个聚簇索引 索引使用时的考虑 检索比率，一般适用于满足条件的数据量少的情况 磁盘访问，内存访问，记录存储 索引与外键 如果没有外键和引用的话，一次修改会导致多次修改 大系统普遍取消外键的关联，取消参照完整性（降低在更新主表时候的过多引用）是提高数据库性能的一个措施。如果有大量的外键关联，则做一次主表查询可能会导致连接多个代码表 索引建立必须要有理由，无论是外键还是其他字段，并不是外键都要添加索引。如果该外键不经常使用就不用添加索引。 如果系统为外键自动添加索引，常常会导致同一字段属于多个索引，为每个外键建立索引，会导致多余索引 系统生成键 系统生成键远好于寻找当前最大值并加1；好于用一个专用表保存下一个值“且加锁更新” 系统生成键是串行插入 如果插入并发性过高，在主键索引的创建操作上会发生严重的资源竞争 解决方案：反向键索引（逆向索引）；哈希索引 系统生成键使用数字比使用字符串效率高 不使用系统生成键，可能会导致插入时主键取值不唯一，有利于主键的唯一性 ###2.2 索引的优点，为什么使用索引？ 什么时候使用B树索引： 仅当要通过索引访问表中很少一部分行 如果要处理表中多行，而且可以使用索引而不用表 索引的5种优点 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，同样可以显着减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 应该建立索引的条件 在经常需要搜索的列上，可以加快搜索的速度； 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； 在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度； 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；外键建索引由于连接加快还会减少死锁几率。 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； 在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。 ###2.3 索引的局限性（索引的限制） 为什么不为每一列建立索引 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 索引会带来的问题 索引有可能降低查询性能，带来磁盘空间的开销和处理开销等 太多的索引，让设计不稳定 对于大量数据检索，索引效率反而更低 创建索引会带来系统的维护和空间的开销 数据修改需求大于检索需求时，索引会降低性能 这些列不应该建立索引 对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少,不利于使用索引。 当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 为什么没有使用我的索引？（不使用索引的情况） 主要是因为：使用索引反而得不到正确结果；或使查询效率变得更慢 情况1：我们在使用B+树索引，而且谓词中没有使用索引的最前列表T，T(X,Y)上有索引，做SELECT * FROM T WHERE Y=5·跳跃式索引（仅CBO） 情况2：使用SELECT COUNT(*) FROM T，而且T上有索引，但是优化器仍然全表扫描，不带任何条件的count会引起全表扫描。 情况3：对于一个有索引的列作出函数查询Select * from t where f(indexed_col) = value 情况4：隐形函数查询（主要是时间和类型变化这种隐形函数查询） 不等于符”&lt;&gt;”会限制索引，引起全表扫描，如果改成or就可以使用索引了。 is null查询条件也会屏蔽索引。 情况5：此时如果用了索引，实际反而会更慢。 数据量本来不够大，oracle自己计算后认为不用索引更合算，则CBO不会选择用索引 情况6：没有正确的统计信息，造成CBO无法做出正确的选择；如果查询优化器认为所有会使查询变慢，则不会使用索引表分析就是收集表和索引的信息，生成的统计信息会存在user_tables这个视图。CBO根据这些信息决定SQL最佳的执行路径。 其他： 对于两个公有字段的表，如果在做外表的表上对该字段建立索引，则该索引不会被使用因为外表的数据访问方式是全表扫描。 查询使用了两个条件用or连接，如果条件1中的字段有索引而条件2中字段没有，则仍会全表扫描。 2.4 IOT 索引组织表索引底层实现 mysql采用B+树而不是B树的原因 索引组织表 OT的用途:全索引表，代码查找表，高频度的一组 关联数据查询 IOT最大的优点:记录是排序的…(效率惊人) 2.5 其他索引 位图索引 主要针对大量相同值的列而创建(例如：类别，操作员，部门ID,库房ID等),索引块的一个索引行中存储键值和起止Rowid,以及这些键值的位置编码,位置编码中的每一位表示键值对应的数据行的有无.一个块可能指向的是几十甚至成百上千行数据的位置.这种方式存储数据,相对于B*Tree索引,占用的空间非常小,创建和使用非常快。 位图索引：非常紧凑，块变得复杂，更新操作会导致整个块被锁住，不利于更新，所以创建位图索引的目的是为了查询而不是为了更行B树索引不能存空值，位图索引可以存空值 哈希索引 所谓Hash索引，实际上就是通过一定的Hash算法，将需要索引的键值进行Hash运算，然后将得到的Hash值存入一个Hash表中。每次需要检索的时候，都会将检索条件进行相同算法的Hash运算，再和Hash表中的Hash值进行比较，并得出相应的信息。HASH索引在有限制条件(需要指定一个确定的值而不是一个值范围)的情况下非常有用。 函数索引 基于函数的索引，类似于普通的索引，只是普通的索引是建立在列上，而它是建立在函数上。当然这回对插入数据有一定影响，因为需要通过函数计算一下，然后生成索引。但是插入数据一般都是少量插入，而查询数据一般数据量比较大。 倒排索引 常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：“单词词典”和“倒排文件”。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://imwyy.github.io/categories/数据库/"}],"tags":[{"name":"干货","slug":"干货","permalink":"http://imwyy.github.io/tags/干货/"},{"name":"数据库","slug":"数据库","permalink":"http://imwyy.github.io/tags/数据库/"}]},{"title":"干货集","slug":"干货","date":"2017-12-11T06:39:36.000Z","updated":"2018-01-08T16:07:12.966Z","comments":true,"path":"2017/12/11/干货/","link":"","permalink":"http://imwyy.github.io/2017/12/11/干货/","excerpt":"","text":"HTTP HTTP报文GET和POST请求的区别HTTP2.0查找树和红黑树TCP/IP","categories":[{"name":"干货","slug":"干货","permalink":"http://imwyy.github.io/categories/干货/"}],"tags":[{"name":"干货","slug":"干货","permalink":"http://imwyy.github.io/tags/干货/"}]},{"title":"rxjava2的disposable","slug":"rxjava2的disposable","date":"2017-12-10T14:54:06.000Z","updated":"2017-12-19T15:32:11.634Z","comments":true,"path":"2017/12/10/rxjava2的disposable/","link":"","permalink":"http://imwyy.github.io/2017/12/10/rxjava2的disposable/","excerpt":"","text":"rxjava+retrofit处理网络请求在使用rxjava+retrofit处理网络请求的时候，一般会采用对观察者进行封装，实现代码复用和拓展。一种可行的封装如下： 基类observer 12345678910111213141516171819202122232425262728293031323334353637383940public abstract class BaseObserver&lt;T&gt; implements Observer&lt;T&gt; &#123; protected String errMsg = \"\"; protected Disposable disposable; @Override public void onSubscribe(Disposable d) &#123; disposable = d; &#125; @Override public void onNext(T t) &#123; &#125; @Override public void onError(Throwable e) &#123; LogUtils.d(\"Subscriber onError\", e.getMessage()); if (!NetworkUtils.isConnected()) &#123; errMsg = \"网络连接出错,\"; &#125; else if (e instanceof APIException) &#123; APIException exception = (APIException) e; errMsg = exception.getMessage() + \", \"; &#125; else if (e instanceof HttpException) &#123; errMsg = \"网络请求出错,\"; &#125; else if (e instanceof IOException) &#123; errMsg = \"网络出错,\"; &#125; if (disposable != null &amp;&amp; !disposable.isDisposed()) &#123; disposable.dispose(); &#125; &#125; @Override public void onComplete() &#123; if (disposable != null &amp;&amp; !disposable.isDisposed()) &#123; disposable.dispose(); &#125; &#125;&#125; 封装请求（登录为例） 这里userService是retrofit接口类 123456789101112 /** * 登录 * @param phone 账号 * @param password 密码 * @param observer 观察者 */ public void login(String phone, String password, BaseObserver&lt;ResponseBean&lt;UidBean&gt;&gt; observer) &#123;// userService.login(new RequestUserBean(phone, EncryptUtils.encryptMD5ToString(password))) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(observer); &#125; 方法调用 1234567891011121314151617APIUser.getInstance().login(phone, password, new BaseObserver&lt;ResponseBean&lt;UidBean&gt;&gt;() &#123; @Override public void onSubscribe(Disposable d) &#123; addDisposable(d); &#125; @Override public void onNext(ResponseBean&lt;UidBean&gt; responseBean) &#123; ToastUtils.showShort(\"登录成功\"); &#125; @Override public void onError(Throwable e) &#123; super.onError(e); ToastUtils.showShort(errMsg+\"登录失败\"); &#125; &#125;); 网上大家对rxjava+retrofit好的封装很多，我这里不再赘述。 关于disposablerxjava虽然好用，但是总所周知，容易遭层内存泄漏。也就说在订阅了事件后没有及时取阅，导致在activity或者fragment销毁后仍然占用着内存，无法释放。而disposable便是这个订阅事件，可以用来取消订阅。但是在什么时候取消订阅呢？我知道有两种方式: 使用CompositeDisposable 看源码，CompositeDisposable的介绍很简单 A disposable container that can hold onto multiple other disposables and offers O(1) add and removal complexity. 一个disposable的容器，可以容纳多个disposable，添加和去除的复杂度为O(1)。这里需要注意的是在该类的addAll方法有这么一句注释 Atomically adds the given array of Disposables to the container or disposes them all if the container has been disposed 也就是说，如果这个CompositeDisposable容器已经是处于dispose的状态，那么所有加进来的disposable都会被自动切断。 所以说可以创建一个BaseActivity，用CompositeDisposable来管理订阅事件disposable，然后在acivity销毁的时候，调用compositeDisposable.dispose()就可以切断所有订阅事件，防止内存泄漏。 在oError和onComplete后调用disposable.dispose();，也就是上面我给的例子中的方法。 查看源码，ObservableCreate的静态类CreateEmitter就是这种方式实现的。同时也可以看到，onError和onComplete不可以同时调用的原因：每次掉用过onError或onComplete其中一个方法后，就会掉用dispose()方法，此时订阅取消，自然也就不能掉用另一个方法了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576static final class CreateEmitter&lt;T&gt; extends AtomicReference&lt;Disposable&gt; implements ObservableEmitter&lt;T&gt;, Disposable &#123; private static final long serialVersionUID = -3434801548987643227L; final Observer&lt;? super T&gt; observer; CreateEmitter(Observer&lt;? super T&gt; observer) &#123; this.observer = observer; &#125; @Override public void onNext(T t) &#123; if (t == null) &#123; onError(new NullPointerException(\"onNext called with null. Null values are generally not allowed in 2.x operators and sources.\")); return; &#125; if (!isDisposed()) &#123; observer.onNext(t); &#125; &#125; @Override public void onError(Throwable t) &#123; if (t == null) &#123; t = new NullPointerException(\"onError called with null. Null values are generally not allowed in 2.x operators and sources.\"); &#125; if (!isDisposed()) &#123; try &#123; observer.onError(t); &#125; finally &#123; dispose(); &#125; &#125; else &#123; RxJavaPlugins.onError(t); &#125; &#125; @Override public void onComplete() &#123; if (!isDisposed()) &#123; try &#123; observer.onComplete(); &#125; finally &#123; dispose(); &#125; &#125; &#125; @Override public void setDisposable(Disposable d) &#123; DisposableHelper.set(this, d); &#125; @Override public void setCancellable(Cancellable c) &#123; setDisposable(new CancellableDisposable(c)); &#125; @Override public ObservableEmitter&lt;T&gt; serialize() &#123; return new SerializedEmitter&lt;T&gt;(this); &#125; @Override public void dispose() &#123; DisposableHelper.dispose(this); &#125; @Override public boolean isDisposed() &#123; return DisposableHelper.isDisposed(get()); &#125; &#125; 除此之外，在github发现一个开源库RxLifecyclee，粗略了解发现他实现的原理是绑定acvitvity是生命周期，在onStart中绑定就在onStop中解绑，其他onResume，onCreate同理。这个和第一种方式似乎又差不多，只不过第一种方式简单，只在ondestory的时候销毁所有事件。 所以那两种方法哪种更好，我也不是很清楚。等到踩到什么坑了可能就知道了。如果某位大佬知道，希望不吝指教。","categories":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/categories/android/"}],"tags":[{"name":"android","slug":"android","permalink":"http://imwyy.github.io/tags/android/"}]},{"title":"安装配置mongoDB","slug":"安装配置mongoDB","date":"2017-12-09T12:27:36.000Z","updated":"2017-12-10T11:16:42.465Z","comments":true,"path":"2017/12/09/安装配置mongoDB/","link":"","permalink":"http://imwyy.github.io/2017/12/09/安装配置mongoDB/","excerpt":"","text":"最近在在学习nodejs，相比mysql，mongodb与nodejs搭配更合适，存储数据格式也比较接近JS对象。关于mysql和mongodb两种类型数据库的差别与对比，下篇文章再写。下面来看一下如何在mac上安装mongodb。 Homebrew你可以选择选择下载mongodb源码编译安装，当然在mac上更方便快捷的方式是用homebrew安装。homebrew是mac上的一个包管理器，相当于ubantu的apt—get。第一次接触homebrew的同学可以戳官网。 安装过程首先在终端输入如下命令更新Homebrew的package数据库 brew update 更新完毕后，接着输入如下命令进行安装mongodb brew install mongodb 安装完成终端大概会出现如下命令123456789101112==&gt; Downloading https://downloads.sf.net/project/machomebrew/Bottles/mongodb-3.4######################################################################## 100.0%==&gt; Pouring mongodb-3.4.6.mavericks.bottle.2.tar.gz==&gt; CaveatsTo have launchd start mongodb at login:ln -sfv /usr/local/opt/mongodb/*.plist ~/Library/LaunchAgentsThen to load mongodb now:launchctl load ~/Library/LaunchAgents/homebrew.mxcl.mongodb.plistOr, if you don’t want/need launchctl, you can just run:mongod —config /usr/local/etc/mongod.conf==&gt; Summary/usr/local/Cellar/mongodb/3.4.6: 17 files, 331M 好了现在安装完成。 启动mongbd输入命令 mongod --config /usr/local/etc/mongod.conf 然后在终端输入命令 mongo 出现如下命令则表示启动成功 1234567891011MongoDB shell version v3.4.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.6Server has startup warnings: 2017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] 2017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] ** WARNING: Access control is not enabled for the database.2017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] ** Read and write access to data and configuration is unrestricted.2017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] 2017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] 2017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] ** WARNING: soft rlimits too low. Number of files is 256, should be at least 1000&gt; 终端输入exit可以退出数据库终端操作。 关闭mongodb1. 使用数据库命令关闭在 数据库操作的终端 依次输入如下命令：12&gt; use admin&gt; db.shutdownServer() 注意这里命令区分大小写。 2. 使用kill命令关闭新建终端窗口 输入如下命令 ps -ef | grep mongo 这个命令查看关于mongo的所有进程的所有信息。如下是我输入命令显示的信息。其中第二列数据是pid。最后一列显示了当时启动该进程输入的命令。12501 3734 3693 0 5:28下午 ttys000 0:00.00 grep mongo501 3707 3601 0 5:06下午 ttys001 0:06.13 mongod --auth --port 27017 --dbpath /data/db 再使用kill+pid命令关闭mongo运行的进程。 kill 3707 这种方式一般用于强制关闭。不建议使用。 问题1. 启动时WARNING问题我们在一开始使用mongod --config /usr/local/etc/mongod.conf 启动mongodb时，出现了一大堆提示信息，包括了一些warning，如下：122017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] ** WARNING: Access control is not enabled for the database.2017-08-02T16:21:45.890+0800 I CONTROL [initandlisten] ** Read and write access to data and configuration is unrestricted. 这些warning并不影响使用数据库，但总出现warning看着也很不爽，那这些命令到底是什么呢？怎么解决呢？ 其实，这是新版mongodb要求我们建立一个安全的数据库。对数据库操作权限设置，只能允许授权用户操作制定数据库。在stackoverflow上找到了解决方案。 如果刚刚启动了mongodb请关闭。方法参考上面。 输入如下命令启动mongodb。这里 /data/db是mongodb存放数据的目录。homebrew安装一般会自动创建。1mongod --port 27017 --dbpath /data/db 新建一个终端窗口连接mongodb 1mongo --port 27017 输入如下数据库命令创建用户。 12345678use admindb.createUser( &#123; user: &quot;yourname&quot;, pwd: &quot;yourpwd&quot;, roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125; ] &#125;) 关闭数据库并用如下命令重启。 1mongod --auth --port 27017 --dbpath /data/db 连接数据库。 1mongo --port 27017 -u &quot;yourname&quot; -p &quot;yourpwd&quot; --authenticationDatabase &quot;admin&quot; 好了现在就会发现WARNING不见了。 123MongoDB shell version v3.4.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.6 在使用时，如果要指定某个用户对某个数据库的操作，可以创建用户指定权限。 比如 Tester用户对test数据对操作为可读可写。 123456789use testdb.createUser( &#123; user: &quot;Tester&quot;, pwd: &quot;123&quot;, roles: [ &#123; role: &quot;readWrite&quot;, db: &quot;test&quot; &#125;, &#123; role: &quot;read&quot;, db: &quot;reporting&quot; &#125; ] &#125;) 连接数据库的命令就变成了 1mongo --port 27017 -u &quot;Tester&quot; -p &quot;123&quot; --authenticationDatabase &quot;test&quot; 当然如果nodejs使用mongoose操作mongodb时，连接的命令也需要填充一些参数 1mongoose.createConnection(&apos;localhost&apos;, &apos;test&apos;, 27017, &#123;user: &apos;Tester&apos;, pass: &apos;123&apos;&#125;); ###2. 启动或关闭数据库时Exception问题12345[initandlisten] exception in initAndListen: 20 Attempted to create a lock file on a read-only directory: /data/db, terminating[initandlisten] shutdown: going to close listening sockets...[initandlisten] shutdown: going to flush diaglog...[initandlisten] now exiting[initandlisten] shutting down with code:100 这个问题是因为 只有root对 /data/db可写，但是你在用自己的账户操作，所以可以用一下命令授权解决问题。 sudo chmod -R go+w /data/db 或者 sudo chown -R $USER /data/db 好了文章就写到这里。再遇见什么坑和问题会后续补充。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://imwyy.github.io/categories/数据库/"}],"tags":[{"name":"踩坑","slug":"踩坑","permalink":"http://imwyy.github.io/tags/踩坑/"},{"name":"安装和配置","slug":"安装和配置","permalink":"http://imwyy.github.io/tags/安装和配置/"}]}]}